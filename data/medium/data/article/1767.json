{"name": "1767", "parent": "", "content": "Are There Limits to Online Free Speech\u00a0? When technologists defend free speech above all other values, they play directly into the hands of white nationalists. In November 2016, Twitter shut down the accounts of numerous alt-right leaders and white nationalists. Richard Spencer, the head of the National Policy Institute and a vocal neo-Nazi, told the LA Times it was a violation of his free speech. \u201c[Twitter needs] to issue some kind of apology and make it clear they are not going to crack down on viewpoints. Are they going to now ban Donald Trump\u2019s account?\u201d Old and new media organizations are scrambling to define acceptable speech in the era of President Trump. But Twitter is in a particularly poor position. The prevalence of hateful speech and harassment on the platform scared off potential acquisitions by both Disney and Salesforce. The company has dealt with one PR disaster after another, from Ghostbusters star Leslie Jones temporarily leaving the platform after being harassed and doxed, to a viral video of obscene and abusive tweets sent to female sports journalists, to pro-Trump accounts sending Newsweek reporter Kurt Eichenwald animated gifs designed to induce epileptic seizures. A site once touted as \u201cthe free speech wing of the free speech party\u201d is now best known for giving a voice to Donald Trump and #gamergaters. At the same time, attempts by Twitter and sites with similar histories of free speech protections to regulate the more offensive content on their site have been met with furious accusations of censorship and pandering to political correctness. This enables the alt-right to position themselves as victims, and left-wing SJWs (\u201csocial justice warriors\u201d) as aggressors. Never mind that private companies can establish whatever content restrictions they wish, and that virtually all these companies already have such guidelines on the books, even if they are weakly enforced. When technology companies appear to abandon their long-standing commitment to the First Amendment due to the concerns of journalists, feminists, or activists, the protests of those banned or regulated can seem sympathetic. How did we get to the point where Twitter eggs spewing anti-Semitic insults are seen as defenders of free speech? To answer this question, we have to delve into why sites like Reddit and Twitter have historically been fiercely committed to freedom of speech. There are three reasons: But a commitment to freedom of speech above all else presumes an idealistic version of the internet that no longer exists. And as long as we consider any content moderation to be censorship, minority voices will continue to be drowned out by their aggressive majority counterparts. To better understand this, we need to start with the origin story of the modern internet. Like many technology stories, it takes place in Northern California. The Secret Hippie Hacker Past of the\u00a0Internet The American internet was birthed from a counter-culture devoted to freedom, experimentation, transparency and openness. While the internet originates with the military\u200a\u2014\u200aARPANET was commissioned and funded by the Department of Defense\u200a\u2014\u200athe early hardware and applications that helped technology to thrive were mostly created by academics, geeks, hackers and enthusiasts. For instance, in post-hippie Berkeley, early microcomputer aficionados formed the Homebrew Computer Club, freely sharing information that enabled its members to create some of the first personal computers. When Steve Wozniak and Steve Jobs built the first Apple Computer, they gave away its schematics at the Club. (Woz regularly helped his friends build their own Apples.) In the 1980s, people at elite universities and research labs built on ARPANET\u2019s infrastructure to create mailing lists, chat rooms, discussion groups, adventure games, and many other textual ancestors of today\u2019s social media. These were all distributed widely, and for free. Computer created by hippie geeks. | CC BY-SA 2.0-licensed photo by Ed\u00a0Uthman. Today, it boggles the mind that people would give away such valuable intellectual property. But the members of this early computing culture adhered to a loose collection of principles that journalist Steven Levy dubbed \u201cthe hacker ethic\u201d: As I talked to these digital explorers, ranging from those who tamed multimillion-dollar machines in the 1950s to contemporary young wizards who mastered computers in their suburban bedrooms, I found a common element, a common philosophy that seemed tied to the elegantly flowing logic of the computer itself. It was a philosophy of sharing, openness, decentralization, and getting your hands on machines at any cost to improve the machines and to improve the world. This Hacker Ethic is their gift to us: something with value even to those of us with no interest at all in computers. Early technology innovators deeply believed in these values of \u201csharing, openness, and decentralization.\u201d The Homebrew Computer Club\u2019s motto was \u201cgive to help others.\u201d Hackers believed that barriers to improving technology, contributing to knowledge, and innovating should be eliminated. Information should instead be free so that people could improve existing systems and develop new ones. If everyone adhered to the hacker ethic and contributed to their community, they would all benefit from the contributions of others. Now, obviously, these ideals only work if everyone adheres to them. It\u2019s easy to take advantage of other people\u2019s work\u200a\u2014\u200aeconomists call this the \u201cfree rider problem.\u201d And it doesn\u2019t take into account people who aren\u2019t just lazy or selfish, but people who deliberately want to cause harm to others. But these beliefs were built into the very infrastructure of the internet. And they worked, for a time. But regulation was always necessary. Regulating the Early\u00a0Internet On April 12, 1994, a law firm called Canter and Siegel, known as the \u201cGreen Card Lawyers,\u201d sent the first commercial spam e-mail to 6,000 USENET groups advertising their immigration law services. This inspired virulent hatred. Internet users organized a boycott, jammed the firm\u2019s fax, e-mail, and phone lines and set an autodialer to call the lawyers\u2019 home 40 times a day. Canter and Siegel were kicked off three ISP\u2019s before finally finding a home and publishing the early e-marketing book How to Make a Fortune on the Information Superhighway. Despite these dubious successes, the offense was seen as so inappropriate that Canter was finally disbarred in 1997, partially due to the e-mail campaign; William W. Hunt III of the Tennessee Board of Professional Responsibility said, \u201cWe disbarred him and gave him a one-year sentence just to emphasize that his e-mail campaign was a particularly egregious offense.\u201d Early internet adopters were highly educated and relatively young with above average incomes, but, more importantly, many of them were deeply invested in the anti-commercial nature of the emerging internet and the \u201cinformation wants to be free\u201d hacker ethos. Any attempted use of the network for commercial gain was highly discouraged, particularly uses that violated \u201cnetiquette,\u201d the social mores of the internet. Netiquette was a set of community-determined guidelines that were enforced though both norms (people explicitly calling each other out when they violated community standards) and technical means (software that allowed users to block other users). Most USENET groups had lengthy Frequently Asked Questions documents where they spelled out explicitly what was encouraged, tolerated, and disallowed. And users who broke these rules were often sharply reprimanded. The extent of the backlash against Canter and Siegel spam shows not only how egregious a violation of netiquette their messages were, but that their actions threatened the very utility of USENET. If the newsgroups were cluttered with spam, useful messages would be drowned out, interesting discussion would end, and key members would leave. Fast forward a few years and email spam had taken over the inbox. Many internet users used dial-up connections, and resented having to pay to download useless messages about Rolexes and Viagra. By the mid-aughts, email, long a backbone of online communication, had become less useful. So technology companies and computer scientists worked together to develop sophisticated email filters. They don\u2019t work all the time, but people who use commercial email services like Gmail or Hotmail rarely see a spam message in their inbox. The problem was solved technically. In both of these situations, there was no argument that technical and normative ways to circumvent spam violated the free speech rights of spammers. Instead, internet users recognized that the value of their platforms was rooted in their ability to foster communication, and spam was a serious threat. It\u2019s also worth noting that these problems were solved not through government regulation, but through collective action. But today, we face a different set of problems related to free speech online. On one hand, we have aggressive harassment, often organized by particular online communities. On the other, we have platforms that are providing spaces for people with unarguably deplorable values (like neo-Nazis) to congregate. And this is particularly true for sites like Twitter and Reddit, which prioritize freedom of expression over virtually all other values. Free Speech and a Free\u00a0Internet In 1997, the Supreme Court ruled in the landmark Reno v. ACLU case that internet speech deserved the same free speech protections as spoken or written speech. Justice John Paul Stevens wrote in the majority opinion that the internet\u2019s capacity to allow individuals to reach (potentially) mass audiences, made it, perhaps, even more valuable than its broadcast equivalent: Through the use of chat rooms, any person with a phone line can become a town crier with a voice that resonates farther than it could from any soapbox. Through the use of Web pages, mail exploders, and newsgroups, the same individual can become a pamphleteer. The implication is that it was even more important to protect free speech online than offline because of the internet\u2019s wide accessibility. While few people could publish in the New York Times or air their views on 60 Minutes, almost anyone could post their ideas online and make them immediately accessible to millions. Stevens, and many technologists, imagined that the internet would be a powerful check on entrenched interests, especially given the deregulation and consolidation of corporate media begun by Reagan and solidified by Clinton. Such ideals meshed perfectly with the hacker ethic. Rather than corporations or governments having proprietary access to ideas and information, the internet would break down such barriers. These are the ideals behind Wikipedia\u200a\u2014\u200a\u201ca free encyclopedia that anyone can edit,\u201d and Wikileaks\u200a\u2014\u200a\u201cwe open governments.\u201d Protecting internet speech became a primary value of technology communities. Organizations like the ACLU and the EFF dedicated themselves to fighting any encroachment on internet free speech, from over-zealous copyright claims to the jailing of political bloggers. This was furthered by CDA 230: the so-called \u201csafe harbor\u201d provision of the Digital Millennium Copyright Act. CDA 230 holds that \u201conline intermediaries\u201d\u200a\u2014\u200aoriginally ISPs, but now including social media platforms\u200a\u2014\u200aaren\u2019t responsible for the content that their users produce. If I write something libelous about you on Facebook, you can\u2019t sue Facebook for it. If someone writes a horrible comment on a blog I write, that\u2019s not my problem. Basically, CDA 230 enabled user-contributed content (aka social media) to exist. YouTube doesn\u2019t have to review a zillion hours of content before it\u2019s posted; it doesn\u2019t have to censor unpleasant opinions. As a result, CDA 230 is beloved by the tech community and free-speech advocates. The EFF calls it \u201c one of the most valuable tools for protecting freedom of expression and innovation on the Internet.\u201d Now, free speech and progressive ideas have always co-existed uneasily. The ACLU has been attacked from both the left and the right for defending the American Nazi party\u2019s right to march in Skokie, Illinois. In Margaret Atwood\u2019s The Handmaid\u2019s Tale, it\u2019s an unholy alliance between anti-pornography feminists and anti-pornography fundamentalist Christians that leads to the creation of an explicitly patriarchal state. But today, for both liberals and libertarians, the solution to bad speech is more speech. Rather than banning, for instance, racist speech, most First Amendment advocates believe that we should expose its inaccuracy and inconsistencies and combat it through education. (Lawyers call this \u201cthe counterspeech doctrine.\u201d) Sophisticated interpretation of the Counterspeech Doctrine. | CC BY-NC-ND 2.0-licensed photo by\u00a0mpancha. For the most part, this makes sense. Usually, when the government does attempt to regulate internet speech, we end up with poorly conceived legislation. The EFF found that across the Middle East, laws that attempt to shut down terrorist recruiting usually end up being strategically applied to commentary and expression that doesn\u2019t favor the government. And in the US, the Digital Millennium Copyright Act prevents virtually all internet users from using copyrighted content of any kind. A young activist could post an intricate, creative, political video on YouTube\u200a\u2014\u200atypically the type of speech that\u2019s highly protected\u200a\u2014\u200aand it would automatically be taken down if it used a copyrighted song. Few of us want people who refer to the internet as a \u201cseries of tubes\u201d or \u201cthe cyber\u201d making decisions about how the rest of us should use it. If Not the Government, Then\u00a0Who? The problem is that many tech entrepreneurs are still guided by utopian views of the early internet and create products that presume that people are good actors, ignoring considerable evidence to the contrary. The strong antipathy to government regulation and the legal precedent set up by CDA 230 mean that tech companies rely on self-regulation, and when this fails, they are often left scrambling. Image from an ad-filled content farm called \u201cQuotesgram\u201d, click at your own\u00a0risk Let\u2019s take Reddit. Originally a community for geeks to upvote geeky things, Reddit\u2019s current reputation has been tarnished by communities devoted to the alt-right, men\u2019s rights advocacy, and illicit photos of underage girls wearing yoga pants. In 2014, Reddit was heavily criticized for hosting the Fappening, a subreddit devoted to organizing and discussing stolen nude photos of female celebrities. Then-CEO Yishan Wong wrote a blog post called \u201cEvery Man is Responsible for His Own Soul\u201d where he defended Reddit\u2019s choice to continue hosting the subreddit. Wong claimed that Reddit would not use technical means, like banning users or deleting subreddits, to shut down unpleasant content. Instead, they planned to highlight good actors on the site, like Reddit\u2019s popular Secret Santa. (Confusingly, later that day Reddit deleted the subreddit anyway. Pressure and DMCA requests from deep-pocketed celebrity lawyers were apparently enough to outweigh such lofty ideals.) He wrote: The reason is because we consider ourselves not just a company running a website where one can post links and discuss them, but the government of a new type of community. The role and responsibility of a government differs from that of a private corporation, in that it exercises restraint in the usage of its powers. Well, that\u2019s all well and good, but Reddit is not a government. It is a corporation. In the US, the right to free speech applies only when the government attempts to limit what people say, not when private citizens critique media or when websites limit what words people can use in comments. For instance, if Congress passed a bill banning negative comments on Reddit about the President, that would be a legitimate threat to free speech and would be unconstitutional. But if Twitter decides to ban neo-Nazis or terrorist propaganda, that\u2019s perfectly within their right. Sites like Facebook and Instagram aggressively moderate content, which cuts down on the types of organized brigading that happens on Twitter and Reddit. But of course, free speech isn\u2019t just about what\u2019s legal, but about upholding values that are expressed in many places in society. Companies like Twitter and Reddit that have stayed true to hacker ideals of information as free, and of the internet as a haven of free speech, continue to struggle with this balance. ISIS has been extremely effective at using digital media to spread propaganda. The same tools that let people collaborate on awesome projects like Wikipedia also let them collaborate on crazy theories like Pizzagate. Given Reddit\u2019s upvote/downvote infrastructure, it\u2019s hardly surprising that a community devoted to naked pictures of hot famous chicks became the fastest-growing subreddit of all time, regardless of how those pictures were obtained. And Twitter\u2019s feature set is fantastic for people to organize and mobilize quickly, even when those people are virulent anti-Semites. The internet was explicitly founded on idealism. Even though most people are good actors, there are several very vocal minorities who want to use the internet for various Bad Things. Now, this wouldn\u2019t really matter if it was just a matter of counterspeech. If we could end sexism just by pointing out its flaws, then we\u2019d all be in debt to Gender Studies majors. But the type of organized brigading that contemporary social media affords has the intended consequence of deterring other people\u2019s speech\u200a\u2014\u200aspecifically, the speech of women, especially queer women and women of color. And it gives rise to organized movements that want to diminish community trust and belief in institutions. This has very real and very negative consequences. What do we do when tools founded on openness and freedom are used by straight-up bad actors? And what do platforms committed to those ideals do when their technologies are used to harass and suppress others? Who Brought the Alt-Right Into\u00a0This? When technologists defend free speech above all other values, they play directly into the hands of white nationalists. The rise of the alt-right, a fusion of white nationalists, Russian trolls, meme enthusiasts, men\u2019s rights activists, #gamergaters, libertarians, conspiracy theorists, bored teenagers and hardcore right-wing activists has been well-documented by others. Suffice to say that the alt-right has been extraordinarily effective at using digital technologies, from Reddit to 8chan to Twitter to Google Docs, to collaborate, mobilize, and organize. They\u2019ve also been very effective at co-opting the language of left-wing activism to paint themselves as victims. And they\u2019ve done this through claiming the value of free speech. Photo by Sean Barger @waitingfortheman on Instagram To Milo Yiannopolous and his army of Breitbart commentators, safe spaces, inclusive language, and \u201cpolitical correctness\u201d are not attempts to right wrongs, but incursions on free speech. Sexism and racism are lies that feminists, \u201csocial justice warriors,\u201d and others have come up with in order to suppress the truth (or insert your favorite conspiracy theory here). If feminist criticism of sexist imagery in video games functions as censorship, then people who enjoy such games can position themselves as the victims of Big Brother. Not only that, but it allows them to portray feminists as weaklings who can\u2019t handle the harsh realities of everyday life, and need to be coddled and handled carefully\u200a\u2014\u200awhich diminishes very real concerns. They\u2019ve already been extremely successful at positioning college campuses as the worst violators of free speech. Both Yiannopolis and Richard Spencer have garnered great publicity by booking invited talks at college campuses and then delighting in the uproar that typically follows. Campus anti-hate-speech policies have long been targets of the right; add to that anti-bullying and anti-harassment campaigns and you have an environment where Nina Burleigh writes in Newsweek, hardly a bastion of right-wing thought, that \u201cAmerican college campuses are starting to resemble George Orwell\u2019s Oceania with its Thought Police, or East Germany under the Stasi.\u201d (As someone who works in higher ed, this could not be further from the truth.) The idea that college campuses regularly censor and violate the free speech rights of people who aren\u2019t politically correct has become a mainstay of think pieces and Twitter, to my dismay. It\u2019s also given rise to the Professor Watchlist, a directory of \u201ccollege professors who discriminate against conservative students and advance leftist propaganda in the classroom.\u201d (Leftist propaganda, in this case, indicates any anti-capitalist tendencies or acknowledgement of white privilege.) Truthy Meme by the Federalist Papers So when tech companies like Reddit and Twitter, who have always been strong supporters of internet free speech, begin carefully moderating content, the alt-right sees it as full-scale censorship. Ironically, they co-opt the language of the left to portray their critics as aggressive SJWs, and themselves as powerless victims. Content moderation by private technology companies is not a First Amendment violation; in most cases, it\u2019s just a matter of enforcing pre-existing Terms of Service. But this victim/bully dichotomy allows them to garner sympathy from many who truly believe that the internet should be a stronghold of free speech. We need to move beyond this simplistic binary of free speech / censorship online. That is just as true for libertarian-leaning technologists as it is neo-Nazi provocateurs. Sometimes the best way to ensure diverse voices is to make it safe for people to speak up who\u2019d otherwise feel afraid. In his studies of Wikipedia, Northeastern Communication professor Joseph Reagle found that the classic liberal values of the internet\u200a\u2014\u200aopenness, transparency, and freedom\u200a\u2014\u200aprioritize the voices of combative or openly biased community members over the comfort of female members, leading to male domination even in high-minded online communities. Aggressive online speech, whether practiced in the profanity and pornography-laced environment of 4Chan or the loftier venues of newspaper comments sections, positions sexism, racism, and anti-Semitism (and so forth) as issues of freedom of expression rather than structural oppression. Perhaps we might want to look at countries like Canada and the United Kingdom, which take a different approach to free speech than does the United States. These countries recognize that unlimited free speech can lead to aggression and other tactics which end up silencing the speech of minorities\u200a\u2014\u200ain other words, the tyranny of the majority. Creating online communities where all groups can speak may mean scaling back on some of the idealism of the early internet in favor of pragmatism. But recognizing this complexity is an absolutely necessary first step. Thanks to harryh for editing and Lindsay Blackwell & Whitney Phillips for inspiring some of the thoughts behind this piece. Alice E. Marwick is former Director of the McGannon Communication Research Center and Assistant Professor of Communication and Media Studies at Fordham University. She is a 2016\u20132017 fellow at Data & Society. Points/spheres: In \u201cAre There Limits to Online Free Speech?\u201d Alice Marwick argues against simplistic binaries pitting free speech against censorship, looking at how the tech industry\u2019s historic commitment to freedom of speech falls short in the face of organized harassment. This piece is part of a batch of new additions to an ongoing Points series on media, accountability, and the public sphere. See also: ", "title": "Are There Limits to Online Free Speech\u00a0?", "sentences": [{"ab71": "Are There Limits to Online Free Speech\u00a0?"}, {"ede8": "When technologists defend free speech above all other values, they play directly into the hands of white nationalists."}, {"904a": "In November 2016, Twitter shut down the accounts of numerous alt-right leaders and white nationalists. Richard Spencer, the head of the National Policy Institute and a vocal neo-Nazi, told the LA Times it was a violation of his free speech. \u201c[Twitter needs] to issue some kind of apology and make it clear they are not going to crack down on viewpoints. Are they going to now ban Donald Trump\u2019s account?\u201d"}, {"7576": "Old and new media organizations are scrambling to define acceptable speech in the era of President Trump. But Twitter is in a particularly poor position. The prevalence of hateful speech and harassment on the platform scared off potential acquisitions by both Disney and Salesforce. The company has dealt with one PR disaster after another, from Ghostbusters star Leslie Jones temporarily leaving the platform after being harassed and doxed, to a viral video of obscene and abusive tweets sent to female sports journalists, to pro-Trump accounts sending Newsweek reporter Kurt Eichenwald animated gifs designed to induce epileptic seizures. A site once touted as \u201cthe free speech wing of the free speech party\u201d is now best known for giving a voice to Donald Trump and #gamergaters."}, {"f15d": "At the same time, attempts by Twitter and sites with similar histories of free speech protections to regulate the more offensive content on their site have been met with furious accusations of censorship and pandering to political correctness. This enables the alt-right to position themselves as victims, and left-wing SJWs (\u201csocial justice warriors\u201d) as aggressors. Never mind that private companies can establish whatever content restrictions they wish, and that virtually all these companies already have such guidelines on the books, even if they are weakly enforced. When technology companies appear to abandon their long-standing commitment to the First Amendment due to the concerns of journalists, feminists, or activists, the protests of those banned or regulated can seem sympathetic."}, {"f60e": "How did we get to the point where Twitter eggs spewing anti-Semitic insults are seen as defenders of free speech? To answer this question, we have to delve into why sites like Reddit and Twitter have historically been fiercely committed to freedom of speech. There are three reasons:"}, {"0f88": "But a commitment to freedom of speech above all else presumes an idealistic version of the internet that no longer exists. And as long as we consider any content moderation to be censorship, minority voices will continue to be drowned out by their aggressive majority counterparts."}, {"c56c": "To better understand this, we need to start with the origin story of the modern internet. Like many technology stories, it takes place in Northern California."}, {"1e0c": "The Secret Hippie Hacker Past of the\u00a0Internet"}, {"1c76": "The American internet was birthed from a counter-culture devoted to freedom, experimentation, transparency and openness. While the internet originates with the military\u200a\u2014\u200aARPANET was commissioned and funded by the Department of Defense\u200a\u2014\u200athe early hardware and applications that helped technology to thrive were mostly created by academics, geeks, hackers and enthusiasts."}, {"b25e": "For instance, in post-hippie Berkeley, early microcomputer aficionados formed the Homebrew Computer Club, freely sharing information that enabled its members to create some of the first personal computers. When Steve Wozniak and Steve Jobs built the first Apple Computer, they gave away its schematics at the Club. (Woz regularly helped his friends build their own Apples.) In the 1980s, people at elite universities and research labs built on ARPANET\u2019s infrastructure to create mailing lists, chat rooms, discussion groups, adventure games, and many other textual ancestors of today\u2019s social media. These were all distributed widely, and for free."}, {"8ddb": "Computer created by hippie geeks. | CC BY-SA 2.0-licensed photo by Ed\u00a0Uthman."}, {"41d7": "Today, it boggles the mind that people would give away such valuable intellectual property. But the members of this early computing culture adhered to a loose collection of principles that journalist Steven Levy dubbed \u201cthe hacker ethic\u201d:"}, {"7209": "As I talked to these digital explorers, ranging from those who tamed multimillion-dollar machines in the 1950s to contemporary young wizards who mastered computers in their suburban bedrooms, I found a common element, a common philosophy that seemed tied to the elegantly flowing logic of the computer itself. It was a philosophy of sharing, openness, decentralization, and getting your hands on machines at any cost to improve the machines and to improve the world. This Hacker Ethic is their gift to us: something with value even to those of us with no interest at all in computers."}, {"d25d": "Early technology innovators deeply believed in these values of \u201csharing, openness, and decentralization.\u201d The Homebrew Computer Club\u2019s motto was \u201cgive to help others.\u201d Hackers believed that barriers to improving technology, contributing to knowledge, and innovating should be eliminated. Information should instead be free so that people could improve existing systems and develop new ones. If everyone adhered to the hacker ethic and contributed to their community, they would all benefit from the contributions of others."}, {"30fa": "Now, obviously, these ideals only work if everyone adheres to them. It\u2019s easy to take advantage of other people\u2019s work\u200a\u2014\u200aeconomists call this the \u201cfree rider problem.\u201d And it doesn\u2019t take into account people who aren\u2019t just lazy or selfish, but people who deliberately want to cause harm to others."}, {"35a0": "But these beliefs were built into the very infrastructure of the internet. And they worked, for a time. But regulation was always necessary."}, {"f853": "Regulating the Early\u00a0Internet"}, {"b457": "On April 12, 1994, a law firm called Canter and Siegel, known as the \u201cGreen Card Lawyers,\u201d sent the first commercial spam e-mail to 6,000 USENET groups advertising their immigration law services. This inspired virulent hatred. Internet users organized a boycott, jammed the firm\u2019s fax, e-mail, and phone lines and set an autodialer to call the lawyers\u2019 home 40 times a day. Canter and Siegel were kicked off three ISP\u2019s before finally finding a home and publishing the early e-marketing book How to Make a Fortune on the Information Superhighway. Despite these dubious successes, the offense was seen as so inappropriate that Canter was finally disbarred in 1997, partially due to the e-mail campaign; William W. Hunt III of the Tennessee Board of Professional Responsibility said, \u201cWe disbarred him and gave him a one-year sentence just to emphasize that his e-mail campaign was a particularly egregious offense.\u201d"}, {"c682": "Early internet adopters were highly educated and relatively young with above average incomes, but, more importantly, many of them were deeply invested in the anti-commercial nature of the emerging internet and the \u201cinformation wants to be free\u201d hacker ethos. Any attempted use of the network for commercial gain was highly discouraged, particularly uses that violated \u201cnetiquette,\u201d the social mores of the internet. Netiquette was a set of community-determined guidelines that were enforced though both norms (people explicitly calling each other out when they violated community standards) and technical means (software that allowed users to block other users). Most USENET groups had lengthy Frequently Asked Questions documents where they spelled out explicitly what was encouraged, tolerated, and disallowed. And users who broke these rules were often sharply reprimanded."}, {"88a2": "The extent of the backlash against Canter and Siegel spam shows not only how egregious a violation of netiquette their messages were, but that their actions threatened the very utility of USENET. If the newsgroups were cluttered with spam, useful messages would be drowned out, interesting discussion would end, and key members would leave."}, {"ff67": "Fast forward a few years and email spam had taken over the inbox. Many internet users used dial-up connections, and resented having to pay to download useless messages about Rolexes and Viagra. By the mid-aughts, email, long a backbone of online communication, had become less useful. So technology companies and computer scientists worked together to develop sophisticated email filters. They don\u2019t work all the time, but people who use commercial email services like Gmail or Hotmail rarely see a spam message in their inbox. The problem was solved technically."}, {"53eb": "In both of these situations, there was no argument that technical and normative ways to circumvent spam violated the free speech rights of spammers. Instead, internet users recognized that the value of their platforms was rooted in their ability to foster communication, and spam was a serious threat. It\u2019s also worth noting that these problems were solved not through government regulation, but through collective action."}, {"a767": "But today, we face a different set of problems related to free speech online. On one hand, we have aggressive harassment, often organized by particular online communities. On the other, we have platforms that are providing spaces for people with unarguably deplorable values (like neo-Nazis) to congregate. And this is particularly true for sites like Twitter and Reddit, which prioritize freedom of expression over virtually all other values."}, {"6548": "Free Speech and a Free\u00a0Internet"}, {"8e38": "In 1997, the Supreme Court ruled in the landmark Reno v. ACLU case that internet speech deserved the same free speech protections as spoken or written speech. Justice John Paul Stevens wrote in the majority opinion that the internet\u2019s capacity to allow individuals to reach (potentially) mass audiences, made it, perhaps, even more valuable than its broadcast equivalent:"}, {"ba15": "Through the use of chat rooms, any person with a phone line can become a town crier with a voice that resonates farther than it could from any soapbox. Through the use of Web pages, mail exploders, and newsgroups, the same individual can become a pamphleteer."}, {"a410": "The implication is that it was even more important to protect free speech online than offline because of the internet\u2019s wide accessibility. While few people could publish in the New York Times or air their views on 60 Minutes, almost anyone could post their ideas online and make them immediately accessible to millions. Stevens, and many technologists, imagined that the internet would be a powerful check on entrenched interests, especially given the deregulation and consolidation of corporate media begun by Reagan and solidified by Clinton."}, {"4d0f": "Such ideals meshed perfectly with the hacker ethic. Rather than corporations or governments having proprietary access to ideas and information, the internet would break down such barriers. These are the ideals behind Wikipedia\u200a\u2014\u200a\u201ca free encyclopedia that anyone can edit,\u201d and Wikileaks\u200a\u2014\u200a\u201cwe open governments.\u201d Protecting internet speech became a primary value of technology communities. Organizations like the ACLU and the EFF dedicated themselves to fighting any encroachment on internet free speech, from over-zealous copyright claims to the jailing of political bloggers."}, {"ead0": "This was furthered by CDA 230: the so-called \u201csafe harbor\u201d provision of the Digital Millennium Copyright Act. CDA 230 holds that \u201conline intermediaries\u201d\u200a\u2014\u200aoriginally ISPs, but now including social media platforms\u200a\u2014\u200aaren\u2019t responsible for the content that their users produce. If I write something libelous about you on Facebook, you can\u2019t sue Facebook for it. If someone writes a horrible comment on a blog I write, that\u2019s not my problem. Basically, CDA 230 enabled user-contributed content (aka social media) to exist. YouTube doesn\u2019t have to review a zillion hours of content before it\u2019s posted; it doesn\u2019t have to censor unpleasant opinions. As a result, CDA 230 is beloved by the tech community and free-speech advocates. The EFF calls it \u201c one of the most valuable tools for protecting freedom of expression and innovation on the Internet.\u201d"}, {"c564": "Now, free speech and progressive ideas have always co-existed uneasily. The ACLU has been attacked from both the left and the right for defending the American Nazi party\u2019s right to march in Skokie, Illinois. In Margaret Atwood\u2019s The Handmaid\u2019s Tale, it\u2019s an unholy alliance between anti-pornography feminists and anti-pornography fundamentalist Christians that leads to the creation of an explicitly patriarchal state. But today, for both liberals and libertarians, the solution to bad speech is more speech. Rather than banning, for instance, racist speech, most First Amendment advocates believe that we should expose its inaccuracy and inconsistencies and combat it through education. (Lawyers call this \u201cthe counterspeech doctrine.\u201d)"}, {"c56f": "Sophisticated interpretation of the Counterspeech Doctrine. | CC BY-NC-ND 2.0-licensed photo by\u00a0mpancha."}, {"a6da": "For the most part, this makes sense. Usually, when the government does attempt to regulate internet speech, we end up with poorly conceived legislation. The EFF found that across the Middle East, laws that attempt to shut down terrorist recruiting usually end up being strategically applied to commentary and expression that doesn\u2019t favor the government. And in the US, the Digital Millennium Copyright Act prevents virtually all internet users from using copyrighted content of any kind. A young activist could post an intricate, creative, political video on YouTube\u200a\u2014\u200atypically the type of speech that\u2019s highly protected\u200a\u2014\u200aand it would automatically be taken down if it used a copyrighted song. Few of us want people who refer to the internet as a \u201cseries of tubes\u201d or \u201cthe cyber\u201d making decisions about how the rest of us should use it."}, {"add1": "If Not the Government, Then\u00a0Who?"}, {"7424": "The problem is that many tech entrepreneurs are still guided by utopian views of the early internet and create products that presume that people are good actors, ignoring considerable evidence to the contrary. The strong antipathy to government regulation and the legal precedent set up by CDA 230 mean that tech companies rely on self-regulation, and when this fails, they are often left scrambling."}, {"3c61": "Image from an ad-filled content farm called \u201cQuotesgram\u201d, click at your own\u00a0risk"}, {"038d": "Let\u2019s take Reddit. Originally a community for geeks to upvote geeky things, Reddit\u2019s current reputation has been tarnished by communities devoted to the alt-right, men\u2019s rights advocacy, and illicit photos of underage girls wearing yoga pants. In 2014, Reddit was heavily criticized for hosting the Fappening, a subreddit devoted to organizing and discussing stolen nude photos of female celebrities. Then-CEO Yishan Wong wrote a blog post called \u201cEvery Man is Responsible for His Own Soul\u201d where he defended Reddit\u2019s choice to continue hosting the subreddit. Wong claimed that Reddit would not use technical means, like banning users or deleting subreddits, to shut down unpleasant content. Instead, they planned to highlight good actors on the site, like Reddit\u2019s popular Secret Santa. (Confusingly, later that day Reddit deleted the subreddit anyway. Pressure and DMCA requests from deep-pocketed celebrity lawyers were apparently enough to outweigh such lofty ideals.) He wrote:"}, {"58cf": "The reason is because we consider ourselves not just a company running a website where one can post links and discuss them, but the government of a new type of community. The role and responsibility of a government differs from that of a private corporation, in that it exercises restraint in the usage of its powers."}, {"6cd5": "Well, that\u2019s all well and good, but Reddit is not a government. It is a corporation. In the US, the right to free speech applies only when the government attempts to limit what people say, not when private citizens critique media or when websites limit what words people can use in comments. For instance, if Congress passed a bill banning negative comments on Reddit about the President, that would be a legitimate threat to free speech and would be unconstitutional."}, {"82e2": "But if Twitter decides to ban neo-Nazis or terrorist propaganda, that\u2019s perfectly within their right. Sites like Facebook and Instagram aggressively moderate content, which cuts down on the types of organized brigading that happens on Twitter and Reddit. But of course, free speech isn\u2019t just about what\u2019s legal, but about upholding values that are expressed in many places in society."}, {"27d4": "Companies like Twitter and Reddit that have stayed true to hacker ideals of information as free, and of the internet as a haven of free speech, continue to struggle with this balance. ISIS has been extremely effective at using digital media to spread propaganda. The same tools that let people collaborate on awesome projects like Wikipedia also let them collaborate on crazy theories like Pizzagate. Given Reddit\u2019s upvote/downvote infrastructure, it\u2019s hardly surprising that a community devoted to naked pictures of hot famous chicks became the fastest-growing subreddit of all time, regardless of how those pictures were obtained. And Twitter\u2019s feature set is fantastic for people to organize and mobilize quickly, even when those people are virulent anti-Semites."}, {"37ea": "The internet was explicitly founded on idealism. Even though most people are good actors, there are several very vocal minorities who want to use the internet for various Bad Things. Now, this wouldn\u2019t really matter if it was just a matter of counterspeech. If we could end sexism just by pointing out its flaws, then we\u2019d all be in debt to Gender Studies majors. But the type of organized brigading that contemporary social media affords has the intended consequence of deterring other people\u2019s speech\u200a\u2014\u200aspecifically, the speech of women, especially queer women and women of color. And it gives rise to organized movements that want to diminish community trust and belief in institutions. This has very real and very negative consequences."}, {"7e76": "What do we do when tools founded on openness and freedom are used by straight-up bad actors? And what do platforms committed to those ideals do when their technologies are used to harass and suppress others?"}, {"68a3": "Who Brought the Alt-Right Into\u00a0This?"}, {"f8f4": "When technologists defend free speech above all other values, they play directly into the hands of white nationalists."}, {"f49b": "The rise of the alt-right, a fusion of white nationalists, Russian trolls, meme enthusiasts, men\u2019s rights activists, #gamergaters, libertarians, conspiracy theorists, bored teenagers and hardcore right-wing activists has been well-documented by others. Suffice to say that the alt-right has been extraordinarily effective at using digital technologies, from Reddit to 8chan to Twitter to Google Docs, to collaborate, mobilize, and organize. They\u2019ve also been very effective at co-opting the language of left-wing activism to paint themselves as victims. And they\u2019ve done this through claiming the value of free speech."}, {"0aa5": "Photo by Sean Barger @waitingfortheman on Instagram"}, {"43bf": "To Milo Yiannopolous and his army of Breitbart commentators, safe spaces, inclusive language, and \u201cpolitical correctness\u201d are not attempts to right wrongs, but incursions on free speech. Sexism and racism are lies that feminists, \u201csocial justice warriors,\u201d and others have come up with in order to suppress the truth (or insert your favorite conspiracy theory here). If feminist criticism of sexist imagery in video games functions as censorship, then people who enjoy such games can position themselves as the victims of Big Brother. Not only that, but it allows them to portray feminists as weaklings who can\u2019t handle the harsh realities of everyday life, and need to be coddled and handled carefully\u200a\u2014\u200awhich diminishes very real concerns."}, {"77db": "They\u2019ve already been extremely successful at positioning college campuses as the worst violators of free speech. Both Yiannopolis and Richard Spencer have garnered great publicity by booking invited talks at college campuses and then delighting in the uproar that typically follows. Campus anti-hate-speech policies have long been targets of the right; add to that anti-bullying and anti-harassment campaigns and you have an environment where Nina Burleigh writes in Newsweek, hardly a bastion of right-wing thought, that \u201cAmerican college campuses are starting to resemble George Orwell\u2019s Oceania with its Thought Police, or East Germany under the Stasi.\u201d (As someone who works in higher ed, this could not be further from the truth.) The idea that college campuses regularly censor and violate the free speech rights of people who aren\u2019t politically correct has become a mainstay of think pieces and Twitter, to my dismay. It\u2019s also given rise to the Professor Watchlist, a directory of \u201ccollege professors who discriminate against conservative students and advance leftist propaganda in the classroom.\u201d (Leftist propaganda, in this case, indicates any anti-capitalist tendencies or acknowledgement of white privilege.)"}, {"f9c7": "Truthy Meme by the Federalist Papers"}, {"9632": "So when tech companies like Reddit and Twitter, who have always been strong supporters of internet free speech, begin carefully moderating content, the alt-right sees it as full-scale censorship. Ironically, they co-opt the language of the left to portray their critics as aggressive SJWs, and themselves as powerless victims. Content moderation by private technology companies is not a First Amendment violation; in most cases, it\u2019s just a matter of enforcing pre-existing Terms of Service. But this victim/bully dichotomy allows them to garner sympathy from many who truly believe that the internet should be a stronghold of free speech."}, {"b129": "We need to move beyond this simplistic binary of free speech / censorship online. That is just as true for libertarian-leaning technologists as it is neo-Nazi provocateurs. Sometimes the best way to ensure diverse voices is to make it safe for people to speak up who\u2019d otherwise feel afraid. In his studies of Wikipedia, Northeastern Communication professor Joseph Reagle found that the classic liberal values of the internet\u200a\u2014\u200aopenness, transparency, and freedom\u200a\u2014\u200aprioritize the voices of combative or openly biased community members over the comfort of female members, leading to male domination even in high-minded online communities. Aggressive online speech, whether practiced in the profanity and pornography-laced environment of 4Chan or the loftier venues of newspaper comments sections, positions sexism, racism, and anti-Semitism (and so forth) as issues of freedom of expression rather than structural oppression."}, {"1241": "Perhaps we might want to look at countries like Canada and the United Kingdom, which take a different approach to free speech than does the United States. These countries recognize that unlimited free speech can lead to aggression and other tactics which end up silencing the speech of minorities\u200a\u2014\u200ain other words, the tyranny of the majority. Creating online communities where all groups can speak may mean scaling back on some of the idealism of the early internet in favor of pragmatism. But recognizing this complexity is an absolutely necessary first step."}, {"740f": "Thanks to harryh for editing and Lindsay Blackwell & Whitney Phillips for inspiring some of the thoughts behind this piece."}, {"47dd": "Alice E. Marwick is former Director of the McGannon Communication Research Center and Assistant Professor of Communication and Media Studies at Fordham University. She is a 2016\u20132017 fellow at Data & Society."}, {"4548": "Points/spheres: In \u201cAre There Limits to Online Free Speech?\u201d Alice Marwick argues against simplistic binaries pitting free speech against censorship, looking at how the tech industry\u2019s historic commitment to freedom of speech falls short in the face of organized harassment. This piece is part of a batch of new additions to an ongoing Points series on media, accountability, and the public sphere. See also:"}], "child": "1767_1\t1767_2\t1767_3\t1767_4\t1767_5\t1767_6\t1767_7\t1767_8\t1767_9\t1767_10\t1767_11\t1767_12\t1767_13\t1767_14\t1767_15\t1767_16\t1767_17\t1767_18\t1767_19\t1767_20\t1767_21\t1767_22\t1767_23\t1767_24\t1767_251767_1\t1767_2\t1767_3\t1767_4\t1767_5\t1767_6\t1767_7\t1767_8\t1767_9\t1767_10\t1767_11\t1767_12\t1767_13\t1767_14\t1767_15\t1767_16\t1767_17\t1767_18\t1767_19\t1767_20\t1767_21\t1767_22\t1767_23\t1767_24\t1767_251767_1\t1767_2\t1767_3\t1767_4\t1767_5\t1767_6\t1767_7\t1767_8\t1767_9\t1767_10\t1767_11\t1767_12\t1767_13\t1767_14\t1767_15\t1767_16\t1767_17\t1767_18\t1767_19\t1767_20\t1767_21\t1767_22\t1767_23\t1767_24\t1767_25"}