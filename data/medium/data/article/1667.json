{"name": "1667", "parent": "", "content": "4 Approaches To Natural Language Processing & Understanding In 1971, Terry Winograd wrote the SHRDLU program while completing his PhD at MIT. SHRDLU features a world of toy blocks where the computer translates human commands into physical actions, such as \u201cmove the red pyramid next to the blue cube.\u201d To succeed at such tasks, the computer must build up semantic knowledge iteratively, a process Winograd discovered as brittle and limited. The rise of chatbots and voice activated technologies has renewed fervor in natural language processing (NLP) and natural language understanding (NLU) techniques that can produce satisfying human-computer dialogs. Unfortunately, academic breakthroughs have not yet translated into improved user experience. Gizmodo writer Darren Orf declared Messenger chatbots \u201cfrustrating and useless\u201d and Facebook admitted a 70% failure rate for their highly anticipated conversational assistant, \u201cM.\u201d Nevertheless, researchers forge ahead with new plans of attack, occasionally revisiting the same tactics and principles Winograd tried in the 70s. OpenAI recently leveraged reinforcement learning to teach to agents to design their own language by \u201cdropping them into a set of simple worlds, giving them the ability to communicate, and then giving them goals that can be best achieved by communicating with other agents.\u201d The agents independently developed a simple \u201cgrounded\u201d language. MIT Media Lab presents this satisfying clarification on what \u201cgrounded\u201d means in the context of language: \u201cLanguage is grounded in experience. Unlike dictionaries which define words in terms of other words, humans understand many basic words in terms of associations with sensory-motor experiences. People must interact physically with their world to grasp the essence of words like \u201cred,\u201d \u201cheavy,\u201d and \u201cabove.\u201d Abstract words are acquired only in relation to more concretely grounded terms. Grounding is thus a fundamental aspect of spoken language, which enables humans to acquire and to use words and sentences in context.\u201d The antithesis of grounded language is inferred language. Inferred language derives meaning from words themselves rather than what they represent. When trained only on large corpuses of text\u200a\u2014\u200abut not on real-world representations\u200a\u2014\u200astatistical methods for NLP and NLU lack true understanding of what words mean. OpenAI points out that such approaches share the weaknesses revealed by John Searle\u2019s famous Chinese Room thought experiment. Equipped with a universal dictionary to map all possible Chinese input sentences to Chinese output sentences, anyone can perform a brute force lookup and produce conversationally acceptable answers without understanding what they\u2019re actually saying. Why Is Language So\u00a0Complex? Percy Liang, a Stanford CS professor and NLP expert, breaks down the various approaches to NLP / NLU into four distinct categories: First, a brief linguistics lesson before we continue on to define and describe those categories. There are three levels of linguistic analysis: Drawing upon a programming analogy, Liang likens successful syntax to \u201cno compiler errors,\u201d semantics to \u201cno implementation bugs,\u201d and pragmatics to \u201cimplemented the right algorithm.\u201d He highlights that sentences can have the same semantics, yet different syntax, such as \u201c3+2\u201d versus \u201c2+3\u201d. Similarly, they can have identical syntax yet different syntax, for example 3/2 is interpreted differently in Python 2.7 vs Python 3. Ultimately, pragmatics is key, since language is created from the need to motivate an action in the world. If you implement a complex neural network to model a simple coin flip, you have excellent semantics but poor pragmatics since there are a plethora of easier and more efficient approaches to solve the same problem. Plenty of other linguistics terms exist which demonstrate the complexity of language. Words take on different meanings when combined with other words, such as \u201clight\u201d versus \u201clight bulb\u201d (that is, multi-word expressions), or used in various sentences such as \u201cI stepped into the light\u201d and \u201cthe suitcase was light\u201d (polysemy). Hyponymy shows how a specific instance is related to a general term (a cat is a mammal) and meronymy denotes that one term is a part of another (a cat has a tail). Such relationships must be understood to perform the task of textual entailment, recognizing when one sentence is logically entailed in another. \u201cYou\u2019re reading this article\u201d entails the sentence \u201cyou can read.\u201d Aside from complex lexical relationships, your sentences also involve beliefs, conversational implicatures, and presuppositions. Liang provides excellent examples of each. Superman and Clark Kent are the same person, but Lois Lane believes Superman is a hero while Clark Kent is not. If you say \u201cWhere is the roast beef?\u201d and your conversation partner replies \u201cWell, the dog looks happy\u201d, the conversational implicature is the dog ate the roast beef. Presuppositions are background assumptions that are true regardless of the truth value of a sentence. \u201cI have stopped eating meat\u201d has the presupposition \u201cI once ate meat\u201d even if you inverted the sentence to \u201cI have not stopped eating meat.\u201d Adding to the complexity are vagueness, ambiguity, and uncertainty. Uncertainty is when you see a word you don\u2019t know and must guess at the meaning. If you\u2019re stalking a crush on Facebook and their relationship status says \u201cIt\u2019s Complicated\u201d, you already understand vagueness. Richard Socher, Chief Scientist at Salesforce, gave an excellent example of ambiguity at a recent AI conference: \u201cThe question \u2018can I cut you?\u2019 means very different things if I\u2019m standing next to you in line or if I am holding a knife.\u201d Now that you\u2019re more enlightened about the myriad challenges of language, let\u2019s return to Liang\u2019s four categories of approaches to semantic analysis in NLP and NLU. #1: Distributional Approaches Distributional approaches include the large-scale statistical tactics of machine learning and deep learning. These methods typically turn content into word vectors for mathematical analysis and perform quite well at tasks such as part-of-speech tagging (is this a noun or a verb?), dependency parsing (does this part of a sentence modify another part?), and semantic relatedness (are these different words used in similar ways?). These NLP tasks don\u2019t rely on understanding the meaning of words, but rather on the relationship between words themselves. Such systems are broad, flexible, and scalable. They can be applied widely to different types of text without the need for hand-engineered features or expert-encoded domain knowledge. The downside is that they lack true understanding of real-world semantics and pragmatics. Comparing words to other words, or words to sentences, or sentences to sentences can all result in different outcomes. Semantic similarity, for example, does not mean synonymy. A nearest neighbor calculation may even deem antonyms as related: Advanced modern neural network models, such as the end-to-end attentional memory networks pioneered by Facebook or the joint multi-task model invented by Salesforce can handle simple question and answering tasks, but are still in early pilot stages for consumer and enterprise use cases. Thus far, Facebook has only publicly shown that a neural network trained on an absurdly simplified version of The Lord of The Rings can figure out where the elusive One Ring is located. Although distributional methods achieve breadth, they cannot handle depth. Complex and nuanced questions that rely linguistic sophistication and contextual world knowledge have yet to be answered satisfactorily. #2: Frame-Based Approach \u201cA frame is a data-structure for representing a stereotyped situation,\u201d explains Marvin Minsky in his seminal 1974 paper called \u201cA Framework For Representing Knowledge.\u201d Think of frames as a canonical representation for which specifics can be interchanged. Liang provides the example of a commercial transaction as a frame. In such situations, you typically have a seller, a buyers, goods being exchanged, and an exchange price. Sentences that are syntactically different but semantically identical\u200a\u2014\u200asuch as \u201cCynthia sold Bob the bike for $200\u201d and \u201cBob bought the bike for $200 from Cynthia\u201d\u200a\u2014\u200acan be fit into the same frame. Parsing then entails first identifying the frame being used, then populating the specific frame parameters\u200a\u2014\u200ai.e. Cynthia, $200. The obvious downside of frames is that they require supervision. In some domains, an expert must create them, which limits the scope of frame-based approaches. Frames are also necessarily incomplete. Sentences such as \u201cCynthia visited the bike shop yesterday\u201d and \u201cCynthia bought the cheapest bike\u201d cannot be adequately analyzed with the frame we defined above. #3: Model-Theoretical Approach The third category of semantic analysis falls under the model-theoretical approach. To understand this approach, we\u2019ll introduce two important linguistic concepts: \u201cmodel theory\u201d and \u201ccompositionality\u201d. Model theory refers to the idea that sentences refer to the world, as in the case with grounded language (i.e. the block is blue). In compositionality, meanings of the parts of a sentence can be combined to deduce the whole meaning. Liang compares this approach to turning language into computer programs. To determine the answer to the query \u201cwhat is the largest city in Europe by population\u201d, you first have to identify the concepts of \u201ccity\u201d and \u201cEurope\u201d and funnel down your search space to cities contained in Europe. Then you would need to sort the population numbers for each city you\u2019ve shortlisted so far and return the maximum of this value. To execute the sentence \u201cRemind me to buy milk after my last meeting on Monday\u201d requires similar composition breakdown and recombination. Models vary from needing heavy-handed supervision by experts to light supervision from average humans on Mechanical Turk. The advantages of model-based methods include full-world representation, rich semantics, and end-to-end processing, which enable such approaches to answer difficult and nuanced search queries. The major con is that the applications are heavily limited in scope due to the need for hand-engineered features. Applications of model-theoretic approaches to NLU generally start from the easiest, most contained use cases and advance from there. The holy grail of NLU is both breadth and depth, but in practice you need to trade off between them. Distributional methods have scale and breadth, but shallow understanding. Model-theoretical methods are labor-intensive and narrow in scope. Frame-based methods lie in between. #4: Interactive Learning Approaches Paul Grice, a British philosopher of language, described language as a cooperative game between speaker and listener. Liang is inclined to agree. He believes that a viable approach to tackling both breadth and depth in language learning is to employ interactive, interactive environments where humans teach computers gradually. In such approaches, the pragmatic needs of language inform the development. To test this theory, Liang developed SHRDLRN as a modern-day version of Winograd\u2019s SHRDLU. In this interactive language game, a human must instruct a computer to move blocks from a starting orientation to an end orientation. The challenge is that the computer starts with no concept of language. Step by step, the human says a sentence and then visually indicates to the computer what the result of the execution should look like. If a human plays well, he or she adopts consistent language that enables the computer to rapidly build a model of the game environment and map words to colors or positions. The surprising result is that any language will do, even individually invented shorthand notation, as long as you are consistent. The worst players who take the longest to train the computer often employ inconsistent terminology or illogical steps. Liang\u2019s bet is that such approaches would enable computers to solve NLP and NLU problems end-to-end without explicit models. \u201cLanguage is intrinsically interactive,\u201d he adds. \u201cHow do we represent knowledge, context, memory? Maybe we shouldn\u2019t be focused on creating better models, but rather better environments for interactive learning.\u201d Language is both logical and emotional. We use words to describe both math and poetry. Accommodating the wide range of our expressions in NLP and NLU applications may entail combining the approaches outlined above, ranging from the distributional / breadth-focused methods to model-based systems to interactive learning environments. We may also need to re-think our approaches entirely, using interactive human-computer based cooperative learning rather than researcher-driven models. If you have a spare hour and a half, I highly recommend you watch Percy Liang\u2019s entire talk which this summary article was based on: A special thanks to Melissa Fabros for recommending Percy\u2019s talk, Matthew Kleinsmith for highlighting the MIT Media Lab definition of \u201cgrounded\u201d language, and Jeremy Howard and Rachel Thomas of fast.ai for facilitating our connection and conversation. If you enjoyed my article, join the TOPBOTS community and get the best bot news and exclusive industry content. ", "title": "4 Approaches To Natural Language Processing & Understanding", "sentences": [{"592c": "4 Approaches To Natural Language Processing & Understanding"}, {"3224": "In 1971, Terry Winograd wrote the SHRDLU program while completing his PhD at MIT."}, {"b6b1": "SHRDLU features a world of toy blocks where the computer translates human commands into physical actions, such as \u201cmove the red pyramid next to the blue cube.\u201d"}, {"a63d": "To succeed at such tasks, the computer must build up semantic knowledge iteratively, a process Winograd discovered as brittle and limited."}, {"a76e": "The rise of chatbots and voice activated technologies has renewed fervor in natural language processing (NLP) and natural language understanding (NLU) techniques that can produce satisfying human-computer dialogs."}, {"653a": "Unfortunately, academic breakthroughs have not yet translated into improved user experience. Gizmodo writer Darren Orf declared Messenger chatbots \u201cfrustrating and useless\u201d and Facebook admitted a 70% failure rate for their highly anticipated conversational assistant, \u201cM.\u201d"}, {"1e22": "Nevertheless, researchers forge ahead with new plans of attack, occasionally revisiting the same tactics and principles Winograd tried in the 70s."}, {"6aa4": "OpenAI recently leveraged reinforcement learning to teach to agents to design their own language by \u201cdropping them into a set of simple worlds, giving them the ability to communicate, and then giving them goals that can be best achieved by communicating with other agents.\u201d The agents independently developed a simple \u201cgrounded\u201d language."}, {"cbab": "MIT Media Lab presents this satisfying clarification on what \u201cgrounded\u201d means in the context of language:"}, {"e591": "\u201cLanguage is grounded in experience. Unlike dictionaries which define words in terms of other words, humans understand many basic words in terms of associations with sensory-motor experiences. People must interact physically with their world to grasp the essence of words like \u201cred,\u201d \u201cheavy,\u201d and \u201cabove.\u201d Abstract words are acquired only in relation to more concretely grounded terms. Grounding is thus a fundamental aspect of spoken language, which enables humans to acquire and to use words and sentences in context.\u201d"}, {"9c6c": "The antithesis of grounded language is inferred language. Inferred language derives meaning from words themselves rather than what they represent."}, {"e0e7": "When trained only on large corpuses of text\u200a\u2014\u200abut not on real-world representations\u200a\u2014\u200astatistical methods for NLP and NLU lack true understanding of what words mean."}, {"69b4": "OpenAI points out that such approaches share the weaknesses revealed by John Searle\u2019s famous Chinese Room thought experiment. Equipped with a universal dictionary to map all possible Chinese input sentences to Chinese output sentences, anyone can perform a brute force lookup and produce conversationally acceptable answers without understanding what they\u2019re actually saying."}, {"79d8": "Why Is Language So\u00a0Complex?"}, {"88e4": "Percy Liang, a Stanford CS professor and NLP expert, breaks down the various approaches to NLP / NLU into four distinct categories:"}, {"515c": "First, a brief linguistics lesson before we continue on to define and describe those categories."}, {"6b57": "There are three levels of linguistic analysis:"}, {"9722": "Drawing upon a programming analogy, Liang likens successful syntax to \u201cno compiler errors,\u201d semantics to \u201cno implementation bugs,\u201d and pragmatics to \u201cimplemented the right algorithm.\u201d"}, {"1df2": "He highlights that sentences can have the same semantics, yet different syntax, such as \u201c3+2\u201d versus \u201c2+3\u201d. Similarly, they can have identical syntax yet different syntax, for example 3/2 is interpreted differently in Python 2.7 vs Python 3."}, {"9768": "Ultimately, pragmatics is key, since language is created from the need to motivate an action in the world. If you implement a complex neural network to model a simple coin flip, you have excellent semantics but poor pragmatics since there are a plethora of easier and more efficient approaches to solve the same problem."}, {"3af1": "Plenty of other linguistics terms exist which demonstrate the complexity of language. Words take on different meanings when combined with other words, such as \u201clight\u201d versus \u201clight bulb\u201d (that is, multi-word expressions), or used in various sentences such as \u201cI stepped into the light\u201d and \u201cthe suitcase was light\u201d (polysemy)."}, {"80c8": "Hyponymy shows how a specific instance is related to a general term (a cat is a mammal) and meronymy denotes that one term is a part of another (a cat has a tail). Such relationships must be understood to perform the task of textual entailment, recognizing when one sentence is logically entailed in another. \u201cYou\u2019re reading this article\u201d entails the sentence \u201cyou can read.\u201d"}, {"4171": "Aside from complex lexical relationships, your sentences also involve beliefs, conversational implicatures, and presuppositions. Liang provides excellent examples of each. Superman and Clark Kent are the same person, but Lois Lane believes Superman is a hero while Clark Kent is not."}, {"1d4a": "If you say \u201cWhere is the roast beef?\u201d and your conversation partner replies \u201cWell, the dog looks happy\u201d, the conversational implicature is the dog ate the roast beef."}, {"141e": "Presuppositions are background assumptions that are true regardless of the truth value of a sentence. \u201cI have stopped eating meat\u201d has the presupposition \u201cI once ate meat\u201d even if you inverted the sentence to \u201cI have not stopped eating meat.\u201d"}, {"a4ed": "Adding to the complexity are vagueness, ambiguity, and uncertainty. Uncertainty is when you see a word you don\u2019t know and must guess at the meaning."}, {"6f6d": "If you\u2019re stalking a crush on Facebook and their relationship status says \u201cIt\u2019s Complicated\u201d, you already understand vagueness. Richard Socher, Chief Scientist at Salesforce, gave an excellent example of ambiguity at a recent AI conference: \u201cThe question \u2018can I cut you?\u2019 means very different things if I\u2019m standing next to you in line or if I am holding a knife.\u201d"}, {"08c5": "Now that you\u2019re more enlightened about the myriad challenges of language, let\u2019s return to Liang\u2019s four categories of approaches to semantic analysis in NLP and NLU."}, {"3230": "#1: Distributional Approaches"}, {"94f6": "Distributional approaches include the large-scale statistical tactics of machine learning and deep learning. These methods typically turn content into word vectors for mathematical analysis and perform quite well at tasks such as part-of-speech tagging (is this a noun or a verb?), dependency parsing (does this part of a sentence modify another part?), and semantic relatedness (are these different words used in similar ways?). These NLP tasks don\u2019t rely on understanding the meaning of words, but rather on the relationship between words themselves."}, {"0622": "Such systems are broad, flexible, and scalable. They can be applied widely to different types of text without the need for hand-engineered features or expert-encoded domain knowledge. The downside is that they lack true understanding of real-world semantics and pragmatics. Comparing words to other words, or words to sentences, or sentences to sentences can all result in different outcomes."}, {"3fc6": "Semantic similarity, for example, does not mean synonymy. A nearest neighbor calculation may even deem antonyms as related:"}, {"68cf": "Advanced modern neural network models, such as the end-to-end attentional memory networks pioneered by Facebook or the joint multi-task model invented by Salesforce can handle simple question and answering tasks, but are still in early pilot stages for consumer and enterprise use cases."}, {"b39d": "Thus far, Facebook has only publicly shown that a neural network trained on an absurdly simplified version of The Lord of The Rings can figure out where the elusive One Ring is located."}, {"6c9a": "Although distributional methods achieve breadth, they cannot handle depth. Complex and nuanced questions that rely linguistic sophistication and contextual world knowledge have yet to be answered satisfactorily."}, {"fe8f": "#2: Frame-Based Approach"}, {"1e5b": "\u201cA frame is a data-structure for representing a stereotyped situation,\u201d explains Marvin Minsky in his seminal 1974 paper called \u201cA Framework For Representing Knowledge.\u201d Think of frames as a canonical representation for which specifics can be interchanged."}, {"8111": "Liang provides the example of a commercial transaction as a frame. In such situations, you typically have a seller, a buyers, goods being exchanged, and an exchange price."}, {"628b": "Sentences that are syntactically different but semantically identical\u200a\u2014\u200asuch as \u201cCynthia sold Bob the bike for $200\u201d and \u201cBob bought the bike for $200 from Cynthia\u201d\u200a\u2014\u200acan be fit into the same frame. Parsing then entails first identifying the frame being used, then populating the specific frame parameters\u200a\u2014\u200ai.e. Cynthia, $200."}, {"ecdb": "The obvious downside of frames is that they require supervision. In some domains, an expert must create them, which limits the scope of frame-based approaches. Frames are also necessarily incomplete. Sentences such as \u201cCynthia visited the bike shop yesterday\u201d and \u201cCynthia bought the cheapest bike\u201d cannot be adequately analyzed with the frame we defined above."}, {"a806": "#3: Model-Theoretical Approach"}, {"e6cd": "The third category of semantic analysis falls under the model-theoretical approach. To understand this approach, we\u2019ll introduce two important linguistic concepts: \u201cmodel theory\u201d and \u201ccompositionality\u201d."}, {"777b": "Model theory refers to the idea that sentences refer to the world, as in the case with grounded language (i.e. the block is blue). In compositionality, meanings of the parts of a sentence can be combined to deduce the whole meaning."}, {"a680": "Liang compares this approach to turning language into computer programs. To determine the answer to the query \u201cwhat is the largest city in Europe by population\u201d, you first have to identify the concepts of \u201ccity\u201d and \u201cEurope\u201d and funnel down your search space to cities contained in Europe. Then you would need to sort the population numbers for each city you\u2019ve shortlisted so far and return the maximum of this value."}, {"fb79": "To execute the sentence \u201cRemind me to buy milk after my last meeting on Monday\u201d requires similar composition breakdown and recombination."}, {"f23b": "Models vary from needing heavy-handed supervision by experts to light supervision from average humans on Mechanical Turk. The advantages of model-based methods include full-world representation, rich semantics, and end-to-end processing, which enable such approaches to answer difficult and nuanced search queries."}, {"00fc": "The major con is that the applications are heavily limited in scope due to the need for hand-engineered features. Applications of model-theoretic approaches to NLU generally start from the easiest, most contained use cases and advance from there."}, {"dcc7": "The holy grail of NLU is both breadth and depth, but in practice you need to trade off between them. Distributional methods have scale and breadth, but shallow understanding. Model-theoretical methods are labor-intensive and narrow in scope. Frame-based methods lie in between."}, {"872f": "#4: Interactive Learning Approaches"}, {"8c8b": "Paul Grice, a British philosopher of language, described language as a cooperative game between speaker and listener. Liang is inclined to agree. He believes that a viable approach to tackling both breadth and depth in language learning is to employ interactive, interactive environments where humans teach computers gradually. In such approaches, the pragmatic needs of language inform the development."}, {"9c92": "To test this theory, Liang developed SHRDLRN as a modern-day version of Winograd\u2019s SHRDLU. In this interactive language game, a human must instruct a computer to move blocks from a starting orientation to an end orientation. The challenge is that the computer starts with no concept of language. Step by step, the human says a sentence and then visually indicates to the computer what the result of the execution should look like."}, {"6680": "If a human plays well, he or she adopts consistent language that enables the computer to rapidly build a model of the game environment and map words to colors or positions. The surprising result is that any language will do, even individually invented shorthand notation, as long as you are consistent."}, {"21e0": "The worst players who take the longest to train the computer often employ inconsistent terminology or illogical steps."}, {"a764": "Liang\u2019s bet is that such approaches would enable computers to solve NLP and NLU problems end-to-end without explicit models. \u201cLanguage is intrinsically interactive,\u201d he adds. \u201cHow do we represent knowledge, context, memory? Maybe we shouldn\u2019t be focused on creating better models, but rather better environments for interactive learning.\u201d"}, {"e71d": "Language is both logical and emotional. We use words to describe both math and poetry. Accommodating the wide range of our expressions in NLP and NLU applications may entail combining the approaches outlined above, ranging from the distributional / breadth-focused methods to model-based systems to interactive learning environments."}, {"f3d3": "We may also need to re-think our approaches entirely, using interactive human-computer based cooperative learning rather than researcher-driven models."}, {"54e3": "If you have a spare hour and a half, I highly recommend you watch Percy Liang\u2019s entire talk which this summary article was based on:"}, {"106b": "A special thanks to Melissa Fabros for recommending Percy\u2019s talk, Matthew Kleinsmith for highlighting the MIT Media Lab definition of \u201cgrounded\u201d language, and Jeremy Howard and Rachel Thomas of fast.ai for facilitating our connection and conversation."}, {"1d35": "If you enjoyed my article, join the TOPBOTS community and get the best bot news and exclusive industry content."}], "child": "1667_11667_1"}