{"name": "4_21", "child": "", "content": "I did examine the distribution of Rotten Tomatoes\u2019s audience scores, but I found no reason why I should use it as reference to control for the tomatometer variable. This is how the distribution for audience scores looks like:  However, you raised indeed a serious issue about the randomization process. I have thought and still do that each tomatometer rating\u200a\u2014\u200aespecially those for recent movies with few reviews\u200a\u2014\u200aface a potential randomization problem, and there\u2019s an inherent danger for a skewed, non-representative average. But I reasoned that that was not my problem, but rather theirs. I collected the data a user can see and easily access on each website. If the ratings are averages of non-randomized samples, then that should somehow be reflected in the distributions. Those at Metacritic face the same problem with the metascore. Perhaps that\u2019s the main reason they add weighting coefficients to each rating derived from a review: to prevent non-randomization. For the tomatometer, they don\u2019t do any weighting, not to say that it\u2019s not even a classical rating, as I explained in the article. Perhaps that\u2019s why the distribution of the tomatometer took a totally unexpected shape. My only concern was for the randomization and representativeness of the sample I have worked with. And the distribution of the 4917-movies sample for IMDB gave me a good reason to consider my working sample representative. P.S. Thanks for taking the time to write a response! ", "title": "", "parent": "4", "creatorid": "205c2f307347", "id": "dfd976c0bb45"}