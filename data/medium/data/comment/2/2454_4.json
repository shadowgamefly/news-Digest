{"parent": "2454", "content": "And won\u2019t this sooner or later backfire on our internal neural network? If we can\u2019t understand the process/decision of an external neural network, why do we believe we can understand our own? Consciousness seem far from transparent. If a self-driving car accident can blame it on the neural network, to a degree this also holds for us. Maybe AI neural networks need another \u2018rationalizing\u2019 abstraction-layer which could also give an appropriate explanation of behaviour in the same way humans rationalize behaviour even when we don\u2019t really know why. An AI rationalizing machine might be better at it than humans\u00a0\u2026 ", "title": "", "id": "277389194876", "name": "2454_4", "username": "noemata_26242", "timestamp": 1492596483470, "creatorid": "325167d4541e", "child": ""}