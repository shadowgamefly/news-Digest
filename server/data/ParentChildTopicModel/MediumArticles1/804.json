{"name": "804", "parent": "", "title": "I wrote a programming language. Here\u2019s how you can,\u00a0too.", "sentences": [{"df64": "I wrote a programming language. Here\u2019s how you can,\u00a0too."}, {"8ccb": "Over the past 6 months, I\u2019ve been working on a programming language called Pinecone. I wouldn\u2019t call it mature yet, but it already has enough features working to be usable, such as:"}, {"2dd5": "If you\u2019re interested in it, check out Pinecone\u2019s landing page or its GitHub repo."}, {"4ce5": "I\u2019m not an expert. When I started this project, I had no clue what I was doing, and I still don\u2019t. I\u2019ve taken zero classes on language creation, read only a bit about it online, and did not follow much of the advice I have been given."}, {"72b1": "And yet, I still made a completely new language. And it works. So I must be doing something right."}, {"55cc": "In this post, I\u2019ll dive under the hood and show you the pipeline Pinecone (and other programming languages) use to turn source code into magic."}, {"556d": "I\u2018ll also touch on some of the tradeoffs I\u2019ve had make, and why I made the decisions I did."}, {"1235": "This is by no means a complete tutorial on writing a programming language, but it\u2019s a good starting point if you\u2019re curious about language development."}, {"83d5": "Getting Started"}, {"73f6": "\u201cI have absolutely no idea where I would even start\u201d is something I hear a lot when I tell other developers I\u2019m writing a language. In case that\u2019s your reaction, I\u2019ll now go through some initial decisions that are made and steps that are taken when starting any new language."}, {"fa5d": "Compiled vs Interpreted"}, {"789a": "There are two major types of languages: compiled and interpreted:"}, {"0858": "Technically any language could be compiled or interpreted, but one or the other usually makes more sense for a specific language. Generally, interpreting tends to be more flexible, while compiling tends to have higher performance. But this is only scratching the surface of a very complex topic."}, {"9fe7": "I highly value performance, and I saw a lack of programming languages that are both high performance and simplicity-oriented, so I went with compiled for Pinecone."}, {"b68c": "This was an important decision to make early on, because a lot of language design decisions are affected by it (for example, static typing is a big benefit to compiled languages, but not so much for interpreted ones)."}, {"b90f": "Despite the fact that Pinecone was designed with compiling in mind, it does have a fully functional interpreter which was the only way to run it for a while. There are a number of reasons for this, which I will explain later on."}, {"7c87": "Choosing a\u00a0Language"}, {"ba51": "I know it\u2019s a bit meta, but a programming language is itself a program, and thus you need to write it in a language. I chose C++ because of its performance and large feature set. Also, I actually do enjoy working in C++."}, {"66f3": "If you are writing an interpreted language, it makes a lot of sense to write it in a compiled one (like C, C++ or Swift) because the performance lost in the language of your interpreter and the interpreter that is interpreting your interpreter will compound."}, {"9591": "If you plan to compile, a slower language (like Python or JavaScript) is more acceptable. Compile time may be bad, but in my opinion that isn\u2019t nearly as big a deal as bad run time."}, {"b788": "High Level\u00a0Design"}, {"2486": "A programming language is generally structured as a pipeline. That is, it has several stages. Each stage has data formatted in a specific, well defined way. It also has functions to transform data from each stage to the next."}, {"f80c": "The first stage is a string containing the entire input source file. The final stage is something that can be run. This will all become clear as we go through the Pinecone pipeline step by step."}, {"e2e0": "Lexing"}, {"8cc5": "The first step in most programming languages is lexing, or tokenizing. \u2018Lex\u2019 is short for lexical analysis, a very fancy word for splitting a bunch of text into tokens. The word \u2018tokenizer\u2019 makes a lot more sense, but \u2018lexer\u2019 is so much fun to say that I use it anyway."}, {"8aa2": "Tokens"}, {"a377": "A token is a small unit of a language. A token might be a variable or function name (AKA an identifier), an operator or a number."}, {"79e7": "Task of the\u00a0Lexer"}, {"4d70": "The lexer is supposed to take in a string containing an entire files worth of source code and spit out a list containing every token."}, {"d4d3": "Future stages of the pipeline will not refer back to the original source code, so the lexer must produce all the information needed by them. The reason for this relatively strict pipeline format is that the lexer may do tasks such as removing comments or detecting if something is a number or identifier. You want to keep that logic locked inside the lexer, both so you don\u2019t have to think about these rules when writing the rest of the language, and so you can change this type of syntax all in one place."}, {"f789": "Flex"}, {"e9e2": "The day I started the language, the first thing I wrote was a simple lexer. Soon after, I started learning about tools that would supposedly make lexing simpler, and less buggy."}, {"dea7": "The predominant such tool is Flex, a program that generates lexers. You give it a file which has a special syntax to describe the language\u2019s grammar. From that it generates a C program which lexes a string and produces the desired output."}, {"3651": "My Decision"}, {"e6b0": "I opted to keep the lexer I wrote for the time being. In the end, I didn\u2019t see significant benefits of using Flex, at least not enough to justify adding a dependency and complicating the build process."}, {"88ca": "My lexer is only a few hundred lines long, and rarely gives me any trouble. Rolling my own lexer also gives me more flexibility, such as the ability to add an operator to the language without editing multiple files."}, {"6451": "Parsing"}, {"259d": "The second stage of the pipeline is the parser. The parser turns a list of tokens into a tree of nodes. A tree used for storing this type of data is known as an Abstract Syntax Tree, or AST. At least in Pinecone, the AST does not have any info about types or which identifiers are which. It is simply structured tokens."}, {"cff2": "Parser Duties"}, {"18d7": "The parser adds structure to to the ordered list of tokens the lexer produces. To stop ambiguities, the parser must take into account parenthesis and the order of operations. Simply parsing operators isn\u2019t terribly difficult, but as more language constructs get added, parsing can become very complex."}, {"0381": "Bison"}, {"5ae3": "Again, there was a decision to make involving a third party library. The predominant parsing library is Bison. Bison works a lot like Flex. You write a file in a custom format that stores the grammar information, then Bison uses that to generate a C program that will do your parsing. I did not choose to use Bison."}, {"88fb": "Why Custom Is\u00a0Better"}, {"fea9": "With the lexer, the decision to use my own code was fairly obvious. A lexer is such a trivial program that not writing my own felt almost as silly as not writing my own \u2018left-pad\u2019."}, {"9075": "With the parser, it\u2019s a different matter. My Pinecone parser is currently 750 lines long, and I\u2019ve written three of them because the first two were trash."}, {"73d4": "I originally made my decision for a number of reasons, and while it hasn\u2019t gone completely smoothly, most of them hold true. The major ones are as follows:"}, {"df7f": "In the beginning I wasn\u2019t completely sure if I was going down a viable path, but I was given confidence by what Walter Bright (a developer on an early version of C++, and the creator of the D language) had to say on the topic:"}, {"a979": "\u201cSomewhat more controversial, I wouldn\u2019t bother wasting time with lexer or parser generators and other so-called \u201ccompiler compilers.\u201d They\u2019re a waste of time. Writing a lexer and parser is a tiny percentage of the job of writing a compiler. Using a generator will take up about as much time as writing one by hand, and it will marry you to the generator (which matters when porting the compiler to a new platform). And generators also have the unfortunate reputation of emitting lousy error messages.\u201d"}, {"873e": "Action Tree"}, {"36d6": "We have now left the the area of common, universal terms, or at least I don\u2019t know what the terms are anymore. From my understanding, what I call the \u2018action tree\u2019 is most akin to LLVM\u2019s IR (intermediate representation)."}, {"a6d0": "There is a subtle but very significant difference between the action tree and the abstract syntax tree. It took me quite a while to figure out that there even should be a difference between them (which contributed to the need for rewrites of the parser)."}, {"9163": "Action Tree vs\u00a0AST"}, {"4292": "Put simply, the action tree is the AST with context. That context is info such as what type a function returns, or that two places in which a variable is used are in fact using the same variable. Because it needs to figure out and remember all this context, the code that generates the action tree needs lots of namespace lookup tables and other thingamabobs."}, {"e1e8": "Running the Action\u00a0Tree"}, {"d930": "Once we have the action tree, running the code is easy. Each action node has a function \u2018execute\u2019 which takes some input, does whatever the action should (including possibly calling sub action) and returns the action\u2019s output. This is the interpreter in action."}, {"40d4": "Compiling Options"}, {"8b08": "\u201cBut wait!\u201d I hear you say, \u201cisn\u2019t Pinecone supposed to by compiled?\u201d Yes, it is. But compiling is harder than interpreting. There are a few possible approaches."}, {"56e7": "Build My Own\u00a0Compiler"}, {"ad4a": "This sounded like a good idea to me at first. I do love making things myself, and I\u2019ve been itching for an excuse to get good at assembly."}, {"6492": "Unfortunately, writing a portable compiler is not as easy as writing some machine code for each language element. Because of the number of architectures and operating systems, it is impractical for any individual to write a cross platform compiler backend."}, {"14b3": "Even the teams behind Swift, Rust and Clang don\u2019t want to bother with it all on their own, so instead they all use\u2026"}, {"5e73": "LLVM"}, {"40f2": "LLVM is a collection of compiler tools. It\u2019s basically a library that will turn your language into a compiled executable binary. It seemed like the perfect choice, so I jumped right in. Sadly I didn\u2019t check how deep the water was and I immediately drowned."}, {"5ee1": "LLVM, while not assembly language hard, is gigantic complex library hard. It\u2019s not impossible to use, and they have good tutorials, but I realized I would have to get some practice before I was ready to fully implement a Pinecone compiler with it."}, {"916d": "Transpiling"}, {"93d5": "I wanted some sort of compiled Pinecone and I wanted it fast, so I turned to one method I knew I could make work: transpiling."}, {"1e92": "I wrote a Pinecone to C++ transpiler, and added the ability to automatically compile the output source with GCC. This currently works for almost all Pinecone programs (though there are a few edge cases that break it). It is not a particularly portable or scalable solution, but it works for the time being."}, {"d3eb": "Future"}, {"a150": "Assuming I continue to develop Pinecone, It will get LLVM compiling support sooner or later. I suspect no mater how much I work on it, the transpiler will never be completely stable and the benefits of LLVM are numerous. It\u2019s just a matter of when I have time to make some sample projects in LLVM and get the hang of it."}, {"d05b": "Until then, the interpreter is great for trivial programs and C++ transpiling works for most things that need more performance."}, {"e857": "Conclusion"}, {"02a1": "I hope I\u2019ve made programming languages a little less mysterious for you. If you do want to make one yourself, I highly recommend it. There are a ton of implementation details to figure out but the outline here should be enough to get you going."}, {"2723": "Here is my high level advice for getting started (remember, I don\u2019t really know what I\u2019m doing, so take it with a grain of salt):"}, {"887f": "I have very few regrets when it comes to Pinecone development. I made a number of bad choices along the way, but I have rewritten most of the code affected by such mistakes."}, {"66c3": "Right now, Pinecone is in a good enough state that it functions well and can be easily improved. Writing Pinecone has been a hugely educational and enjoyable experience for me, and it\u2019s just getting started."}], "content": "I wrote a programming language. Here\u2019s how you can,\u00a0too. Over the past 6 months, I\u2019ve been working on a programming language called Pinecone. I wouldn\u2019t call it mature yet, but it already has enough features working to be usable, such as: If you\u2019re interested in it, check out Pinecone\u2019s landing page or its GitHub repo. I\u2019m not an expert. When I started this project, I had no clue what I was doing, and I still don\u2019t. I\u2019ve taken zero classes on language creation, read only a bit about it online, and did not follow much of the advice I have been given. And yet, I still made a completely new language. And it works. So I must be doing something right. In this post, I\u2019ll dive under the hood and show you the pipeline Pinecone (and other programming languages) use to turn source code into magic. I\u2018ll also touch on some of the tradeoffs I\u2019ve had make, and why I made the decisions I did. This is by no means a complete tutorial on writing a programming language, but it\u2019s a good starting point if you\u2019re curious about language development. Getting Started \u201cI have absolutely no idea where I would even start\u201d is something I hear a lot when I tell other developers I\u2019m writing a language. In case that\u2019s your reaction, I\u2019ll now go through some initial decisions that are made and steps that are taken when starting any new language. Compiled vs Interpreted There are two major types of languages: compiled and interpreted: Technically any language could be compiled or interpreted, but one or the other usually makes more sense for a specific language. Generally, interpreting tends to be more flexible, while compiling tends to have higher performance. But this is only scratching the surface of a very complex topic. I highly value performance, and I saw a lack of programming languages that are both high performance and simplicity-oriented, so I went with compiled for Pinecone. This was an important decision to make early on, because a lot of language design decisions are affected by it (for example, static typing is a big benefit to compiled languages, but not so much for interpreted ones). Despite the fact that Pinecone was designed with compiling in mind, it does have a fully functional interpreter which was the only way to run it for a while. There are a number of reasons for this, which I will explain later on. Choosing a\u00a0Language I know it\u2019s a bit meta, but a programming language is itself a program, and thus you need to write it in a language. I chose C++ because of its performance and large feature set. Also, I actually do enjoy working in C++. If you are writing an interpreted language, it makes a lot of sense to write it in a compiled one (like C, C++ or Swift) because the performance lost in the language of your interpreter and the interpreter that is interpreting your interpreter will compound. If you plan to compile, a slower language (like Python or JavaScript) is more acceptable. Compile time may be bad, but in my opinion that isn\u2019t nearly as big a deal as bad run time. High Level\u00a0Design A programming language is generally structured as a pipeline. That is, it has several stages. Each stage has data formatted in a specific, well defined way. It also has functions to transform data from each stage to the next. The first stage is a string containing the entire input source file. The final stage is something that can be run. This will all become clear as we go through the Pinecone pipeline step by step. Lexing The first step in most programming languages is lexing, or tokenizing. \u2018Lex\u2019 is short for lexical analysis, a very fancy word for splitting a bunch of text into tokens. The word \u2018tokenizer\u2019 makes a lot more sense, but \u2018lexer\u2019 is so much fun to say that I use it anyway. Tokens A token is a small unit of a language. A token might be a variable or function name (AKA an identifier), an operator or a number. Task of the\u00a0Lexer The lexer is supposed to take in a string containing an entire files worth of source code and spit out a list containing every token. Future stages of the pipeline will not refer back to the original source code, so the lexer must produce all the information needed by them. The reason for this relatively strict pipeline format is that the lexer may do tasks such as removing comments or detecting if something is a number or identifier. You want to keep that logic locked inside the lexer, both so you don\u2019t have to think about these rules when writing the rest of the language, and so you can change this type of syntax all in one place. Flex The day I started the language, the first thing I wrote was a simple lexer. Soon after, I started learning about tools that would supposedly make lexing simpler, and less buggy. The predominant such tool is Flex, a program that generates lexers. You give it a file which has a special syntax to describe the language\u2019s grammar. From that it generates a C program which lexes a string and produces the desired output. My Decision I opted to keep the lexer I wrote for the time being. In the end, I didn\u2019t see significant benefits of using Flex, at least not enough to justify adding a dependency and complicating the build process. My lexer is only a few hundred lines long, and rarely gives me any trouble. Rolling my own lexer also gives me more flexibility, such as the ability to add an operator to the language without editing multiple files. Parsing The second stage of the pipeline is the parser. The parser turns a list of tokens into a tree of nodes. A tree used for storing this type of data is known as an Abstract Syntax Tree, or AST. At least in Pinecone, the AST does not have any info about types or which identifiers are which. It is simply structured tokens. Parser Duties The parser adds structure to to the ordered list of tokens the lexer produces. To stop ambiguities, the parser must take into account parenthesis and the order of operations. Simply parsing operators isn\u2019t terribly difficult, but as more language constructs get added, parsing can become very complex. Bison Again, there was a decision to make involving a third party library. The predominant parsing library is Bison. Bison works a lot like Flex. You write a file in a custom format that stores the grammar information, then Bison uses that to generate a C program that will do your parsing. I did not choose to use Bison. Why Custom Is\u00a0Better With the lexer, the decision to use my own code was fairly obvious. A lexer is such a trivial program that not writing my own felt almost as silly as not writing my own \u2018left-pad\u2019. With the parser, it\u2019s a different matter. My Pinecone parser is currently 750 lines long, and I\u2019ve written three of them because the first two were trash. I originally made my decision for a number of reasons, and while it hasn\u2019t gone completely smoothly, most of them hold true. The major ones are as follows: In the beginning I wasn\u2019t completely sure if I was going down a viable path, but I was given confidence by what Walter Bright (a developer on an early version of C++, and the creator of the D language) had to say on the topic: \u201cSomewhat more controversial, I wouldn\u2019t bother wasting time with lexer or parser generators and other so-called \u201ccompiler compilers.\u201d They\u2019re a waste of time. Writing a lexer and parser is a tiny percentage of the job of writing a compiler. Using a generator will take up about as much time as writing one by hand, and it will marry you to the generator (which matters when porting the compiler to a new platform). And generators also have the unfortunate reputation of emitting lousy error messages.\u201d Action Tree We have now left the the area of common, universal terms, or at least I don\u2019t know what the terms are anymore. From my understanding, what I call the \u2018action tree\u2019 is most akin to LLVM\u2019s IR (intermediate representation). There is a subtle but very significant difference between the action tree and the abstract syntax tree. It took me quite a while to figure out that there even should be a difference between them (which contributed to the need for rewrites of the parser). Action Tree vs\u00a0AST Put simply, the action tree is the AST with context. That context is info such as what type a function returns, or that two places in which a variable is used are in fact using the same variable. Because it needs to figure out and remember all this context, the code that generates the action tree needs lots of namespace lookup tables and other thingamabobs. Running the Action\u00a0Tree Once we have the action tree, running the code is easy. Each action node has a function \u2018execute\u2019 which takes some input, does whatever the action should (including possibly calling sub action) and returns the action\u2019s output. This is the interpreter in action. Compiling Options \u201cBut wait!\u201d I hear you say, \u201cisn\u2019t Pinecone supposed to by compiled?\u201d Yes, it is. But compiling is harder than interpreting. There are a few possible approaches. Build My Own\u00a0Compiler This sounded like a good idea to me at first. I do love making things myself, and I\u2019ve been itching for an excuse to get good at assembly. Unfortunately, writing a portable compiler is not as easy as writing some machine code for each language element. Because of the number of architectures and operating systems, it is impractical for any individual to write a cross platform compiler backend. Even the teams behind Swift, Rust and Clang don\u2019t want to bother with it all on their own, so instead they all use\u2026 LLVM LLVM is a collection of compiler tools. It\u2019s basically a library that will turn your language into a compiled executable binary. It seemed like the perfect choice, so I jumped right in. Sadly I didn\u2019t check how deep the water was and I immediately drowned. LLVM, while not assembly language hard, is gigantic complex library hard. It\u2019s not impossible to use, and they have good tutorials, but I realized I would have to get some practice before I was ready to fully implement a Pinecone compiler with it. Transpiling I wanted some sort of compiled Pinecone and I wanted it fast, so I turned to one method I knew I could make work: transpiling. I wrote a Pinecone to C++ transpiler, and added the ability to automatically compile the output source with GCC. This currently works for almost all Pinecone programs (though there are a few edge cases that break it). It is not a particularly portable or scalable solution, but it works for the time being. Future Assuming I continue to develop Pinecone, It will get LLVM compiling support sooner or later. I suspect no mater how much I work on it, the transpiler will never be completely stable and the benefits of LLVM are numerous. It\u2019s just a matter of when I have time to make some sample projects in LLVM and get the hang of it. Until then, the interpreter is great for trivial programs and C++ transpiling works for most things that need more performance. Conclusion I hope I\u2019ve made programming languages a little less mysterious for you. If you do want to make one yourself, I highly recommend it. There are a ton of implementation details to figure out but the outline here should be enough to get you going. Here is my high level advice for getting started (remember, I don\u2019t really know what I\u2019m doing, so take it with a grain of salt): I have very few regrets when it comes to Pinecone development. I made a number of bad choices along the way, but I have rewritten most of the code affected by such mistakes. Right now, Pinecone is in a good enough state that it functions well and can be easily improved. Writing Pinecone has been a hugely educational and enjoyable experience for me, and it\u2019s just getting started. ", "child": "804_1\t804_2\t804_3\t804_4\t804_5\t804_6\t804_7\t804_8\t804_9\t804_10\t804_11\t804_12\t804_13\t804_14\t804_15\t804_16\t804_17\t804_18\t804_19\t804_20\t804_21\t804_22\t804_23\t804_24\t804_25"}