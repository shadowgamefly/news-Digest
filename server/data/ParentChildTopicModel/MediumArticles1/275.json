{"name": "275", "parent": "", "title": "The Ghost in the Algorithm", "sentences": [{"c91a": "The Ghost in the Algorithm"}, {"760d": "The necessary struggle to reject \u201ctechnology first\u201d and develop an ethical framework for the automated era"}, {"f0e2": "In our era of \u201cpost-capitalism\u201d, \u201cpost-democracy\u201d, \u201cpost-truth\u201d, \u201cpost-ideology\u201d, \u201calternative facts\u201d, \u201cfake news\u201d and \u201cdishonest media\u201d, we\u2019re certain of almost nothing. But one thing almost all of us agree upon is that, if there ever were to be a match between technology and humankind, we would be betting on the former."}, {"f276": "It is technology that dominates our age. Data is the new oil; Big Data the new everything: healthcare, cities, self-driving cars, delivery drones, and therefore even warfare, even security are going to be \u201cdisrupted\u201d by the \u201csmart\u201d uses enabled by the \u201cInternet of Things\u201d."}, {"8ae6": "Look at market capitalization. Top three are Apple, Alphabet and Microsoft, the Holy Trinity of our connected lives."}, {"de52": "Give a man a smartphone, an operative system and a search engine, and he\u2019ll become a superman, an \u00fcbermensch augmented by technology."}, {"49ab": "Give him even more, many more connected applications\u200a\u2014\u200astarting from a marketplace like Amazon, and a social network like Facebook, who seat comfortably in 4th and 5th position respectively\u200a\u2014\u200aand technology will become part of himself."}, {"87b3": "We are \u201cinforgs\u201d, argues Oxford Professor Luciano Floridi: we are informational entities, bits as much as\u00a0flesh."}, {"bba9": "This comes with an inevitable sense of paranoia, one that is the last remaining \u201cspectre haunting Europe\u201d, and the world. What if technology is the true master? How is it to be slaves bowing to glittering devices, instead of great kings and conquerors? As it turns out after tons of poor, Internet-phobic mainstream journalism, not great at all."}, {"ba58": "Careers end for an automated bias replicated by an indifferent personal rating algorithm stored in some unknown but absolutely crucial database held by Lord knows who, Lord knows where. Social media profiles and email accounts and cloud services are hacked by the thousands, if not millions, leading to spectacular leaks of personal data, financial data, medical data, and sensitive data of all sorts\u200a\u2014\u200aincluding the classified and the intimate\u200a\u2014\u200aall because of the same decision not to adopt two-factor authentication or end-to-end encryption by default."}, {"347d": "And robots are not only going to steal your jobs, but they are going to make decisions in your place, more and more of them; and sure, they are going to be hackable too. They are already."}, {"5cf5": "\u201cYou are not a gadget\u201d, wrote Internet pioneer Jaron Lanier in 2010, and it still perfectly sums up our basic fear about the \u201cdigital revolution\u201d. That it has gone too far, too quick; that it will continue to be so\u200a\u2014\u200athere\u2019s no stopping technology!; and that we have no clue about how to turn the tide in man\u2019s favor."}, {"ed11": "Forget Trump\u2019s \u201cAmerica First\u201d, or Zuckerberg\u2019s \u201cPeople First\u201d: the true ideological motto of our era is \u201cTechnology first\u201d."}, {"331c": "Every time a new problem comes to the fore in the social or political arena, it is first and foremost\u200a\u2014\u200aif not only\u200a\u2014\u200aa technological problem, to be framed in a technological scenario and fixed with a technological solution. Political scientist Evgeny Morozov even has a name for it: \u201csolutionism\u201d."}, {"451c": "Every time politics or the media want to be \u201cnew\u201d, there must be something technological involved: participatory platforms, online referenda, presidential tweets, Facebook Lives, 360 videos, immersive VR reportages, and everything viral."}, {"a833": "It is as if politics could only give second-best answers. As if humans could only be less efficient, less \u201csmart\u201d than machines, and therefore inferior. Some tried to compete by becoming quasi-machines themselves: their movement is called \u201cQuantified Self\u201d, and it basically aims at making a measure out of every human volition, until numbers and thoughts tend to the same utilitarian optimum\u200a\u2014\u200athe intake of calories, the amount of drank water, your heartbeat, all constantly monitored by devices, all digitally perfected."}, {"5f39": "But that\u2019s nothing less than our own, contemporary \u201copium for the masses\u201d. Technological determinism may be comforting for those who radically distrust human beings, but it hides a crucial fact: that each technology has a human creator. And that therefore it is those human creators who constitute the true masters of our era."}, {"b539": "The digital may have revolutionized everything, but it did not let a computer or a robot sit among Forbes\u2019s richest. Bill Gates, not one of the AIs who terrify the Microsoft guru, is the wealthiest man in the world; Mark Zuckerberg, not its News Feed algorithm, climbed to the fifth position, translating the end of our privacy into a 56 billion dollars net worth."}, {"9e8a": "It is man who dominate technology\u200a\u2014\u200ait\u2019s simple, and it\u2019s true. It is human programmers who decide what fundamental ethics should a self-driving AI possess and use in case it is needed to prevent an accident automatically. Even with no human intervention, there is human intervention. There always is."}, {"f6f3": "Algorithms decide who we should most easily interact with, you might reply. Who we actually even see in News Feeds or search results. They manipulate our emotions, as in the ominous Facebook experiment that induced bad feelings in ignorant users just to check whether, on average, they would engage more out of depression and frustration rather than happiness and serenity."}, {"b13a": "News articles seek more and more just about the same: to get more clicks, and to get them now. It is automated bots that serve us with political propaganda, networked activism or sadistic beheadings in the same unwavering manner. Online rating systems decide who we are, what we deserve, what benefits we should be allowed, even what dreams we should be dreaming. \u201cClass\u201d is no longer a political struggle: it strictly belongs to the jargon of information theory."}, {"d352": "After all AIs beat poker pros now, because they are even starting to learn how to cheat\u200a\u2014\u200awe taught them, and they are fast, creative learners."}, {"1f16": "But again, there is a human behind all of this. Call it a programmer, a data scientist, a digital or social media marketing strategist, a storyteller, an alternative facts-checker, a SEO specialist, a deep neural networks researcher\u200a\u2014\u200ait\u2019s still a man. And a man, every man, has ethics. Each and everyone of us is a political actor, with beliefs, prejudices, a peculiar view of the social order and some kind of exposition to ideology."}, {"e9c6": "But if every machine has a human creator, if every automatic decision is actually the result of a set of conditionals written by a human being with a precise ethical and political stance, then machines have ethics too. They could not know about this, and the stances may be not intentionally passed on to the digital replicas, but they would still have it."}, {"dfd1": "Here\u2019s something the \u201cdigital revolution\u201d is about: it is about discussing how to better incorporate ethics in intelligent machines, or in any machine who is entitled with significant choices in our lives. It is a revolution in ethics and politics and sociology as much as it is in technology. The important finding from our reasoning, though, is that those non-technological aspects of the technological revolutions are, in fact, their true constituents. Human thought may have not changed with every new device and processor, but each revolution in devices and processors brought about important ethical decisions about the role of technology in society."}, {"1a2b": "It is these decisions that we have to better investigate. What we should be asking\u200a\u2014\u200anot to the machines, but to the human ghost in the machines\u200a\u2014\u200ais not just, for example, how to secure IoT devices, but why we should be wanting smart cities, smart homes, smart refrigerators, smart roads and the like in the first place, and why would connecting everything be a good thing for society as a whole even if the smart objects could pass the cybersecurity test (spoiler: they can\u2019t)."}, {"9d4d": "We should not be asking what it is safe to share with \u201cfriends\u201d on social media, but why has the act of \u201csharing\u201d become so dominant and pervasive in every human experience. Not how to embed more serendipity in our filter-bubbled News Feed, but how exactly we are indoctrinated with our own social media propaganda (as in Pariser), why we are ignorant of the criteria of content selection, and why we should be accepting such an unregulated activity by a private, for-profit entity at all. Not whether we stand with taxis or Uber, but what it means to live in a driver-less society."}, {"ff16": "This would entail unpacking what Frank Pasquale calls \u201cthe Black Box society\u201d."}, {"2732": "Open the algorithms, make them transparent, and be clear about it: these imperatives, were they to be truly enacted, would reveal how deep into ethics our technological discourse is actually situated. Discussing such kind of issues would hardly require a PhD in Informatics or hacking skills. It would definitely require, though, expertise in philosophy, sociology, psychology, political science, economics, and the law. These are the masters of technology. These explain\u200a\u2014\u200aor try to explain\u200a\u2014\u200awhat goes on in the mind of those who coded, designed, marketed and narrated the details and uses of those technologies. When they don\u2019t, as for most proprietary algorithms of the GAFA-led economic era, it is again for a very human reason."}, {"9e8b": "Profit is a very human reason. And profits grow when technology is king\u200a\u2014\u200afor technological companies, at least. If technology is an indifferent force of history going about its way irrespective of how humans try to plan and modify it, then every technological progress becomes a fact of nature, and it is us who have to adapt to it."}, {"6774": "Ethics is sacrificed from the start: thou shalt not question that this particular instance of technological progress is actually progress for us humans, reads the First Commandment of Silicon Valley; because it is progress by definition\u200a\u2014\u200aand if you fail to see it, you are the problem. Ethics is therefore left as a sort of darwinistic guide for human slavery, in which all you can decide is how to better adapt to a new gadget, social network, or online service\u200a\u2014\u200abut never ask yourself whether those innovations are actually worth the human effort, or even whether with just some slight modifications the amount of social benefit would have been enormously greater."}, {"0d78": "Think of Facebook: it would not be difficult to make it much better for democracy. Post in the News Feed should include news articles that embed the exact opposite of the political values the Facebook algorithm deduced for you. Criteria for the \u201ctrending\u201d section should be public, and intelligible to every new 13-years old\u200a\u2014\u200aor 70+\u200a\u2014\u200asubscriber. Experiments with the News Feed should not be possible without explicit informed consent\u200a\u2014\u200ano, mere acceptance of the ToS should not be considered \u201cinformed consent\u201d by an experimental subject."}, {"2a1e": "Facebook connection should be secure, but https has been rolled out starting from 2011, whereas Facebook was born in 2004, when the technology had been around for a decade already. Our data on the platform should obviously not be used for surveillance and tracking of protesters, and yet\u200a\u2014\u200aeven after the alleged \u201cFacebook revolution\u201d in Arab countries in 2011\u200a\u2014\u200athis has been made into explicit policy only in March 2017."}, {"062c": "This does not mean Facebook is unresponsive to user requests. It is. Zuckerberg is actually known for his adaptation skills\u200a\u2014\u200athink of how nuanced his view of fake news on the platform has become, and how not nuanced it was in the beginning\u200a\u2014\u200aand he\u2019s quite good at politics, so good in fact that many speculate he will run for President sooner than later. The problem is that with no conflict comes no change. And users have come to accept too much, and question too little about Facebook and how it developed while it was conquering the world."}, {"b968": "Is it because many of us are imbued with an ideology that assumes that technological change should not, and cannot, be hindered by politics? Probably. Is it because being on Facebook is much easier and more seductive than reflecting on what it means to live a Facebooked life? Absolutely. My point here, however, is that what we are collectively failing to see is the gigantic transfer of power in the hands of human actors who are not traditionally concerned with deep ethical questions\u200a\u2014\u200aprogrammers, engineers, designers, data scientists etc\u200a\u2014\u200aand yet are now at the very heart of the most fascinating and pressing ethical dilemmas we socially and individually have to face."}, {"084a": "Technically skilled people with no background whatsoever in ethics are nonetheless quickly becoming the masters of ethical decisions. Decisions that are actually being made, on a daily basis, without any of us knowing what it is that motivated them, and how they are effectively implemented."}, {"691b": "Something is happening, however: such a shift could have not gone completely rogue. Research centers, Institutions, experts, even press coverage are more and more dedicated to the thorny issue of ethics in AI, and in fields as diverse as the workplace, the attention and sharing economy, copyright, surveillance, targeted profiling and propaganda. But we are barely scratching the surface. And we have not yet figured out how to make use of ethics as a tradition of thought to inform policies that better serve the public interest of the multitudes of users, rather then the private one of the selected few who happen to shape their experiences."}, {"c2d5": "Do we want our government to be \u201cdata-based\u201d? Would we want it even if it means less democracy in the name of more efficiency, as in Parag Khanna\u2019s \u201cdirect technocracy\u201d?"}, {"f22d": "Do we want our cars to be self-driven, even if it means that someone, somewhere, will always know exactly where we are headed, or can hack into the engine remotely? How would the public react to a terrorist act like the one claimed by ISIS in Niece, but in which the killer truck is self-driven?"}, {"dc10": "Voice computing is great\u200a\u2014\u200abut what about having all of your conversations recorded and stored somewhere, for any jury to hear? It is already happening with Amazon Echo. Is the additional comfort worth the sacrifice in terms of potential loss of freedom?"}, {"af4e": "Algorithms should be fair, not objective\u200a\u2014\u200alike us. But is their unfairness threatening the very notions of democracy and individual rights? As we still lack a comprehensive picture of their impact on our lives, it is hard to tell whether what we need is mandatory legislation to moderate their power on us, or a milder approach based on self-regulation is enough."}, {"a0d0": "Even with a clearer view of the negative effects of AI domination, it won\u2019t be easy to understand in which precise cases we should resort to the former and in which to the latter\u200a\u2014\u200aespecially since one-size-fits-all solutions are not in sight, and it is more than plausible that they can\u2019t possibly exist at all. As EFF\u2019s Kurt Opsahl recently argued at RightsCon, it just takes a data ethics code of conduct to make us legitimately wonder whether its tenets would pose excessive limits on the freedom of expression of programmers."}, {"56f3": "So how can abusive algorithms become human rights-compliant? What kinds of subjects should monitor their compliance and enforce those requirements? Do we need corporate \u201cdata ethics\u201d officers, institutional boards of experts, independent auditing authorities, transparency-enabled crowdsourced public opinion watchdogs\u200a\u2014\u200aor a mixture of all this?"}, {"213c": "Finally, what happens if and when AIs actually gain autonomy to a degree that makes their decisional intelligence effectively comparable to that of humans? Should we be talking of \u201crobot rights\u201d, then? Should autonomous algorithms have their own ethics? Would we be able to recognize it in case they develop a moral system by themselves? And how to make sure their moral principles are actually compatible with those of human judgment about fairness, justice, prejudice, impartiality\u200a\u2014\u200aeven truth?"}, {"4eac": "We have no answers to these questions and, what\u2019s worse, we have no ideology backing a critique to their being not even questions at all. All we are left with is Silicon Valley ideology, in which the only admissible ethics is the utilitarian principle: if it\u2019s faster, cheaper, easier, smarter, then adopt it. In which it is markets who regulate technology, not bureaucracies. And in which most of the times profits get in the same hands: those of technology creators."}, {"8af6": "We should not be accepting this anymore. We should be trying to articulate an ethics for the automated era. Not just philosophers: programmers, designers, data scientists should cooperate in the effort. There\u2019s a long way to go. But we have a starting point: stop saying \u201cTechnology First\u201d. The rest will follow."}], "content": "The Ghost in the Algorithm The necessary struggle to reject \u201ctechnology first\u201d and develop an ethical framework for the automated era In our era of \u201cpost-capitalism\u201d, \u201cpost-democracy\u201d, \u201cpost-truth\u201d, \u201cpost-ideology\u201d, \u201calternative facts\u201d, \u201cfake news\u201d and \u201cdishonest media\u201d, we\u2019re certain of almost nothing. But one thing almost all of us agree upon is that, if there ever were to be a match between technology and humankind, we would be betting on the former. It is technology that dominates our age. Data is the new oil; Big Data the new everything: healthcare, cities, self-driving cars, delivery drones, and therefore even warfare, even security are going to be \u201cdisrupted\u201d by the \u201csmart\u201d uses enabled by the \u201cInternet of Things\u201d. Look at market capitalization. Top three are Apple, Alphabet and Microsoft, the Holy Trinity of our connected lives. Give a man a smartphone, an operative system and a search engine, and he\u2019ll become a superman, an \u00fcbermensch augmented by technology. Give him even more, many more connected applications\u200a\u2014\u200astarting from a marketplace like Amazon, and a social network like Facebook, who seat comfortably in 4th and 5th position respectively\u200a\u2014\u200aand technology will become part of himself. We are \u201cinforgs\u201d, argues Oxford Professor Luciano Floridi: we are informational entities, bits as much as\u00a0flesh. This comes with an inevitable sense of paranoia, one that is the last remaining \u201cspectre haunting Europe\u201d, and the world. What if technology is the true master? How is it to be slaves bowing to glittering devices, instead of great kings and conquerors? As it turns out after tons of poor, Internet-phobic mainstream journalism, not great at all. Careers end for an automated bias replicated by an indifferent personal rating algorithm stored in some unknown but absolutely crucial database held by Lord knows who, Lord knows where. Social media profiles and email accounts and cloud services are hacked by the thousands, if not millions, leading to spectacular leaks of personal data, financial data, medical data, and sensitive data of all sorts\u200a\u2014\u200aincluding the classified and the intimate\u200a\u2014\u200aall because of the same decision not to adopt two-factor authentication or end-to-end encryption by default. And robots are not only going to steal your jobs, but they are going to make decisions in your place, more and more of them; and sure, they are going to be hackable too. They are already. \u201cYou are not a gadget\u201d, wrote Internet pioneer Jaron Lanier in 2010, and it still perfectly sums up our basic fear about the \u201cdigital revolution\u201d. That it has gone too far, too quick; that it will continue to be so\u200a\u2014\u200athere\u2019s no stopping technology!; and that we have no clue about how to turn the tide in man\u2019s favor. Forget Trump\u2019s \u201cAmerica First\u201d, or Zuckerberg\u2019s \u201cPeople First\u201d: the true ideological motto of our era is \u201cTechnology first\u201d. Every time a new problem comes to the fore in the social or political arena, it is first and foremost\u200a\u2014\u200aif not only\u200a\u2014\u200aa technological problem, to be framed in a technological scenario and fixed with a technological solution. Political scientist Evgeny Morozov even has a name for it: \u201csolutionism\u201d. Every time politics or the media want to be \u201cnew\u201d, there must be something technological involved: participatory platforms, online referenda, presidential tweets, Facebook Lives, 360 videos, immersive VR reportages, and everything viral. It is as if politics could only give second-best answers. As if humans could only be less efficient, less \u201csmart\u201d than machines, and therefore inferior. Some tried to compete by becoming quasi-machines themselves: their movement is called \u201cQuantified Self\u201d, and it basically aims at making a measure out of every human volition, until numbers and thoughts tend to the same utilitarian optimum\u200a\u2014\u200athe intake of calories, the amount of drank water, your heartbeat, all constantly monitored by devices, all digitally perfected. But that\u2019s nothing less than our own, contemporary \u201copium for the masses\u201d. Technological determinism may be comforting for those who radically distrust human beings, but it hides a crucial fact: that each technology has a human creator. And that therefore it is those human creators who constitute the true masters of our era. The digital may have revolutionized everything, but it did not let a computer or a robot sit among Forbes\u2019s richest. Bill Gates, not one of the AIs who terrify the Microsoft guru, is the wealthiest man in the world; Mark Zuckerberg, not its News Feed algorithm, climbed to the fifth position, translating the end of our privacy into a 56 billion dollars net worth. It is man who dominate technology\u200a\u2014\u200ait\u2019s simple, and it\u2019s true. It is human programmers who decide what fundamental ethics should a self-driving AI possess and use in case it is needed to prevent an accident automatically. Even with no human intervention, there is human intervention. There always is. Algorithms decide who we should most easily interact with, you might reply. Who we actually even see in News Feeds or search results. They manipulate our emotions, as in the ominous Facebook experiment that induced bad feelings in ignorant users just to check whether, on average, they would engage more out of depression and frustration rather than happiness and serenity. News articles seek more and more just about the same: to get more clicks, and to get them now. It is automated bots that serve us with political propaganda, networked activism or sadistic beheadings in the same unwavering manner. Online rating systems decide who we are, what we deserve, what benefits we should be allowed, even what dreams we should be dreaming. \u201cClass\u201d is no longer a political struggle: it strictly belongs to the jargon of information theory. After all AIs beat poker pros now, because they are even starting to learn how to cheat\u200a\u2014\u200awe taught them, and they are fast, creative learners. But again, there is a human behind all of this. Call it a programmer, a data scientist, a digital or social media marketing strategist, a storyteller, an alternative facts-checker, a SEO specialist, a deep neural networks researcher\u200a\u2014\u200ait\u2019s still a man. And a man, every man, has ethics. Each and everyone of us is a political actor, with beliefs, prejudices, a peculiar view of the social order and some kind of exposition to ideology. But if every machine has a human creator, if every automatic decision is actually the result of a set of conditionals written by a human being with a precise ethical and political stance, then machines have ethics too. They could not know about this, and the stances may be not intentionally passed on to the digital replicas, but they would still have it. Here\u2019s something the \u201cdigital revolution\u201d is about: it is about discussing how to better incorporate ethics in intelligent machines, or in any machine who is entitled with significant choices in our lives. It is a revolution in ethics and politics and sociology as much as it is in technology. The important finding from our reasoning, though, is that those non-technological aspects of the technological revolutions are, in fact, their true constituents. Human thought may have not changed with every new device and processor, but each revolution in devices and processors brought about important ethical decisions about the role of technology in society. It is these decisions that we have to better investigate. What we should be asking\u200a\u2014\u200anot to the machines, but to the human ghost in the machines\u200a\u2014\u200ais not just, for example, how to secure IoT devices, but why we should be wanting smart cities, smart homes, smart refrigerators, smart roads and the like in the first place, and why would connecting everything be a good thing for society as a whole even if the smart objects could pass the cybersecurity test (spoiler: they can\u2019t). We should not be asking what it is safe to share with \u201cfriends\u201d on social media, but why has the act of \u201csharing\u201d become so dominant and pervasive in every human experience. Not how to embed more serendipity in our filter-bubbled News Feed, but how exactly we are indoctrinated with our own social media propaganda (as in Pariser), why we are ignorant of the criteria of content selection, and why we should be accepting such an unregulated activity by a private, for-profit entity at all. Not whether we stand with taxis or Uber, but what it means to live in a driver-less society. This would entail unpacking what Frank Pasquale calls \u201cthe Black Box society\u201d. Open the algorithms, make them transparent, and be clear about it: these imperatives, were they to be truly enacted, would reveal how deep into ethics our technological discourse is actually situated. Discussing such kind of issues would hardly require a PhD in Informatics or hacking skills. It would definitely require, though, expertise in philosophy, sociology, psychology, political science, economics, and the law. These are the masters of technology. These explain\u200a\u2014\u200aor try to explain\u200a\u2014\u200awhat goes on in the mind of those who coded, designed, marketed and narrated the details and uses of those technologies. When they don\u2019t, as for most proprietary algorithms of the GAFA-led economic era, it is again for a very human reason. Profit is a very human reason. And profits grow when technology is king\u200a\u2014\u200afor technological companies, at least. If technology is an indifferent force of history going about its way irrespective of how humans try to plan and modify it, then every technological progress becomes a fact of nature, and it is us who have to adapt to it. Ethics is sacrificed from the start: thou shalt not question that this particular instance of technological progress is actually progress for us humans, reads the First Commandment of Silicon Valley; because it is progress by definition\u200a\u2014\u200aand if you fail to see it, you are the problem. Ethics is therefore left as a sort of darwinistic guide for human slavery, in which all you can decide is how to better adapt to a new gadget, social network, or online service\u200a\u2014\u200abut never ask yourself whether those innovations are actually worth the human effort, or even whether with just some slight modifications the amount of social benefit would have been enormously greater. Think of Facebook: it would not be difficult to make it much better for democracy. Post in the News Feed should include news articles that embed the exact opposite of the political values the Facebook algorithm deduced for you. Criteria for the \u201ctrending\u201d section should be public, and intelligible to every new 13-years old\u200a\u2014\u200aor 70+\u200a\u2014\u200asubscriber. Experiments with the News Feed should not be possible without explicit informed consent\u200a\u2014\u200ano, mere acceptance of the ToS should not be considered \u201cinformed consent\u201d by an experimental subject. Facebook connection should be secure, but https has been rolled out starting from 2011, whereas Facebook was born in 2004, when the technology had been around for a decade already. Our data on the platform should obviously not be used for surveillance and tracking of protesters, and yet\u200a\u2014\u200aeven after the alleged \u201cFacebook revolution\u201d in Arab countries in 2011\u200a\u2014\u200athis has been made into explicit policy only in March 2017. This does not mean Facebook is unresponsive to user requests. It is. Zuckerberg is actually known for his adaptation skills\u200a\u2014\u200athink of how nuanced his view of fake news on the platform has become, and how not nuanced it was in the beginning\u200a\u2014\u200aand he\u2019s quite good at politics, so good in fact that many speculate he will run for President sooner than later. The problem is that with no conflict comes no change. And users have come to accept too much, and question too little about Facebook and how it developed while it was conquering the world. Is it because many of us are imbued with an ideology that assumes that technological change should not, and cannot, be hindered by politics? Probably. Is it because being on Facebook is much easier and more seductive than reflecting on what it means to live a Facebooked life? Absolutely. My point here, however, is that what we are collectively failing to see is the gigantic transfer of power in the hands of human actors who are not traditionally concerned with deep ethical questions\u200a\u2014\u200aprogrammers, engineers, designers, data scientists etc\u200a\u2014\u200aand yet are now at the very heart of the most fascinating and pressing ethical dilemmas we socially and individually have to face. Technically skilled people with no background whatsoever in ethics are nonetheless quickly becoming the masters of ethical decisions. Decisions that are actually being made, on a daily basis, without any of us knowing what it is that motivated them, and how they are effectively implemented. Something is happening, however: such a shift could have not gone completely rogue. Research centers, Institutions, experts, even press coverage are more and more dedicated to the thorny issue of ethics in AI, and in fields as diverse as the workplace, the attention and sharing economy, copyright, surveillance, targeted profiling and propaganda. But we are barely scratching the surface. And we have not yet figured out how to make use of ethics as a tradition of thought to inform policies that better serve the public interest of the multitudes of users, rather then the private one of the selected few who happen to shape their experiences. Do we want our government to be \u201cdata-based\u201d? Would we want it even if it means less democracy in the name of more efficiency, as in Parag Khanna\u2019s \u201cdirect technocracy\u201d? Do we want our cars to be self-driven, even if it means that someone, somewhere, will always know exactly where we are headed, or can hack into the engine remotely? How would the public react to a terrorist act like the one claimed by ISIS in Niece, but in which the killer truck is self-driven? Voice computing is great\u200a\u2014\u200abut what about having all of your conversations recorded and stored somewhere, for any jury to hear? It is already happening with Amazon Echo. Is the additional comfort worth the sacrifice in terms of potential loss of freedom? Algorithms should be fair, not objective\u200a\u2014\u200alike us. But is their unfairness threatening the very notions of democracy and individual rights? As we still lack a comprehensive picture of their impact on our lives, it is hard to tell whether what we need is mandatory legislation to moderate their power on us, or a milder approach based on self-regulation is enough. Even with a clearer view of the negative effects of AI domination, it won\u2019t be easy to understand in which precise cases we should resort to the former and in which to the latter\u200a\u2014\u200aespecially since one-size-fits-all solutions are not in sight, and it is more than plausible that they can\u2019t possibly exist at all. As EFF\u2019s Kurt Opsahl recently argued at RightsCon, it just takes a data ethics code of conduct to make us legitimately wonder whether its tenets would pose excessive limits on the freedom of expression of programmers. So how can abusive algorithms become human rights-compliant? What kinds of subjects should monitor their compliance and enforce those requirements? Do we need corporate \u201cdata ethics\u201d officers, institutional boards of experts, independent auditing authorities, transparency-enabled crowdsourced public opinion watchdogs\u200a\u2014\u200aor a mixture of all this? Finally, what happens if and when AIs actually gain autonomy to a degree that makes their decisional intelligence effectively comparable to that of humans? Should we be talking of \u201crobot rights\u201d, then? Should autonomous algorithms have their own ethics? Would we be able to recognize it in case they develop a moral system by themselves? And how to make sure their moral principles are actually compatible with those of human judgment about fairness, justice, prejudice, impartiality\u200a\u2014\u200aeven truth? We have no answers to these questions and, what\u2019s worse, we have no ideology backing a critique to their being not even questions at all. All we are left with is Silicon Valley ideology, in which the only admissible ethics is the utilitarian principle: if it\u2019s faster, cheaper, easier, smarter, then adopt it. In which it is markets who regulate technology, not bureaucracies. And in which most of the times profits get in the same hands: those of technology creators. We should not be accepting this anymore. We should be trying to articulate an ethics for the automated era. Not just philosophers: programmers, designers, data scientists should cooperate in the effort. There\u2019s a long way to go. But we have a starting point: stop saying \u201cTechnology First\u201d. The rest will follow. ", "child": "275_1\t275_2"}