{"name": "868", "parent": "", "title": "How to build a math expression tokenizer using JavaScript", "sentences": [{"2f63": "How to build a math expression tokenizer using JavaScript"}, {"0928": "Source: Wikimedia Commons"}, {"83a7": "Some time ago, I got inspired to build an app for solving specific kinds of math problems. I discovered I had to parse the expression into an abstract syntax tree, so I decided to build a prototype in Javascript. While working on the parser, I realized the tokenizer had to be built first. I\u2019ll walk you through how to do one yourself. (Warning: its easier than it looks at first.)"}, {"ef3d": "What is a Tokenizer?"}, {"b75e": "A tokenizer is a program that breaks up an expression into units called tokens. For instance, if we have an expression like \u201cI\u2019m a big fat developer\u201d, we could tokenize it in different ways, such as:"}, {"fca7": "Using words as tokens,"}, {"926a": "0 => I\u2019m1 => a2 => big3 => fat4 => developer"}, {"0295": "Using non-whitespace characters as tokens,"}, {"36e6": "0 => I1 => \u20182 => m3 => a4 => b\u202616 => p17 => e18 => r"}, {"ad3c": "We could also consider all characters as tokens, to get"}, {"d39b": "0 => I1 => \u20182 => m3 => (space)4 => a5 => (space)6 => b\u202620 => p21 => e22 => r"}, {"993f": "You get the idea, right?"}, {"0af6": "Tokenizers (also called lexers) are used in the development of compilers for programming languages. They help the compiler make structural sense out of what you are trying to say. In this case, though, we\u2019re building one for math expressions."}, {"7721": "Tokens"}, {"7eb1": "A valid math expression consists of mathematically valid tokens, which for the purposes of this project could be Literals, Variables, Operators or Functions.A few notes on the above:"}, {"b74a": "We\u2019ll also add two tokens that aren\u2019t usually considered tokens, but will help us with clarity: Left and Right Parentheses. You know what those are."}, {"badc": "A Few Considerations"}, {"35fd": "Implicit Multiplication"}, {"b2e6": "Implicit multiplication simply means allowing the user to write \u201cshorthand\u201d multiplications, such as 5x, instead of 5*x. Taking it a step further, it also allows doing that with functions (5sin(x) = 5*sin(x))."}, {"5f1d": "Even further, it allows for 5(x) and 5(sin(x)). We have the option of allowing it or not. Tradeoffs? Not allowing it would actually make tokenizing easier and would allow for multi-letter variable names (names likeprice). Allowing it makes the platform more intuitive to the user, and well, provides an added challenge to overcome. I chose to allow it."}, {"367b": "Syntax"}, {"914e": "While we aren\u2019t creating a programming language, we need to have some rules about what makes a valid expression, so users know what to enter and we know what to plan for. In precise terms, math tokens must be combined according to these syntax rules for the expression to be valid. Here are my rules:"}, {"05bb": "2+3, 2 +3, 2 + 3, 2 + 3 are all OK 5 x - 22, 5x-22, 5x- 22 are all OK"}, {"43ef": "In other words, spacing doesn\u2019t matter (except within a multi-character token like the Literal 22)."}, {"5714": "2. Function arguments have to be in parentheses (sin(y), cos(45), not sin y, cos 45). (Why? We\u2019ll be removing all spaces from the string, so we want to know where a function starts and ends without having to do some \u201cgymnastics\u201d.)"}, {"0eda": "3. Implicit multiplication is allowed only between Literals and Variables, or Literals and Functions, in that order (that is, Literals always come first), and can be with or without parentheses. This means:"}, {"4565": "Now, let\u2019s get to work."}, {"1cc2": "Data Modelling"}, {"1640": "It helps to have a sample expression in your head to test this on. We\u2019ll start with something basic: 2y + 1"}, {"687a": "What we expect is an array that lists the different tokens in the expression, along with their types and values. So for this case, we expect:"}, {"ad78": "0 => Literal (2)1 => Variable (y)2 => Operator (+)3 => Literal (1)"}, {"40eb": "First, we\u2019ll define a Token class to make things easier:"}, {"a45a": "function Token(type, value) {   this.type = type;   this.value = value}"}, {"a931": "Algorithm"}, {"546b": "Next, let\u2019s build the skeleton of our tokenizer function."}, {"8da4": "Our tokenizer will go through each character of the str array and build tokens based on the value it finds."}, {"2f0c": "[Note that we\u2019re assuming the user gives us a valid expression, so we\u2019ll skip any form of validation throughout this project.]"}, {"c6b7": "function tokenize(str) {  var result=[]; //array of tokens    // remove spaces; remember they don't matter?  str.replace(/\\s+/g, \"\");"}, {"6403": "  // convert to array of characters  str=str.split(\"\");"}, {"43fd": "  str.forEach(function (char, idx) {    if(isDigit(char)) {      result.push(new Token(\"Literal\", char));    } else if (isLetter(char)) {      result.push(new Token(\"Variable\", char));    } else if (isOperator(char)) {      result.push(new Token(\"Operator\", char));    } else if (isLeftParenthesis(char)) {      result.push(new Token(\"Left Parenthesis\", char));    } else if (isRightParenthesis(char)) {      result.push(new Token(\"Right Parenthesis\", char));    }  });"}, {"194d": "  return result;}"}, {"3fc5": "The code above is fairly basic. For reference, the helpers isDigit()\u00a0, isLetter(), isOperator(), isLeftParenthesis(), and isRightParenthesis()are defined as follows (don\u2019t be scared by the symbols\u200a\u2014\u200ait\u2019s called regex, and it\u2019s really awesome):"}, {"5d6e": "function isDigit(ch) { return /\\d/.test(ch);}"}, {"13ac": "function isLetter(ch) { return /[a-z]/i.test(ch);}"}, {"de26": "function isOperator(ch) { return /\\+|-|\\*|\\/|\\^/.test(ch);}"}, {"f0c9": "function isLeftParenthesis(ch) { return /\\(/.test(ch);}"}, {"0c30": "function isRightParenthesis(ch) { return /\\)/.test(ch);}"}, {"2cb9": "[Note that there are no isFunction(), isLiteral() or isVariable() functions, because we testing characters individually.]"}, {"308c": "So now our parser actually works. Try it out on these expressions: 2 + 3, 4a + 1, 5x+ (2y), 11 + sin(20.4)."}, {"5355": "All good?"}, {"91eb": "Not quite."}, {"9966": "You\u2019ll observe that for the last expression, 11 is reported as two Literal tokens instead of one. Also sin gets reported as three tokens instead of one. Why is this?"}, {"d783": "Let\u2019s pause for a moment and think about this. We tokenized the array character by character, but actually, some of our tokens can contain multiple characters. For example, Literals can be 5, 7.9,\u00a0.5. Functions can be sin, cos etc. Variables are only single-characters, but can occur together in implicit multiplication. How do we solve this?"}, {"e17a": "Buffers"}, {"94b7": "We can fix this by implementing a buffer. Two, actually. We\u2019ll use one buffer to hold Literal characters (numbers and decimal point), and one for letters (which covers both variables and functions)."}, {"54b5": "How do the buffers work? When the tokenizer encounters a number/decimal point or letter, it pushes it into the appropriate buffer, and keeps doing so until it enters a different kind of operator. Its actions will vary based on the operator."}, {"6673": "For instance, in the expression 456.7xy + 6sin(7.04x), it should go along these lines:"}, {"441f": " read 4 => numberBuffer read 5 => numberBuffer read 6 => numberBuffer read\u00a0. => numberBuffer read 7 => numberBuffer x is\u00a0a\u00a0letter, so put all the contents of numberbuffer together as a Literal 456.7 => result read x => letterBuffer read y => letterBuffer + is an Operator, so remove all the contents of letterbuffer separately as Variables x => result, y => result + => result read 6 => numberBuffer s is a letter, so put all the contents of numberbuffer together as a Literal 6 => result read s => letterBuffer read i => letterBuffer read n => letterBuffer ( is a Left Parenthesis, so put all the contents of letterbuffer together as a function sin => result read 7 => numberBuffer read\u00a0. => numberBuffer read 0 => numberBuffer read 4 => numberBuffer x is a letter, so put all the contents of numberbuffer together as a Literal 7.04 => result read x => letterBuffer ) is a Right Parenthesis, so remove all the contents of letterbuffer separately as Variables x => result"}, {"4d25": "Complete. You get the hang of it now, right?"}, {"edb6": "We\u2019re getting there, just a few more cases to handle."}, {"a5cd": "This is the point where you sit down and think deeply about your algorithm and data modeling. What happens if my current character is an operator, and the numberBuffer is non-empty? Can both buffers ever simultaneously be non-empty?"}, {"dfe1": "Putting it all together, here\u2019s what we come up with (the values to the left of the arrow depict our current character (ch) type, NB=numberbuffer, LB=letterbuffer, LP=left parenthesis, RP=right parenthesis"}, {"0784": "loop through the array:  what type is ch?"}, {"a9b1": "  digit => push ch to NB  decimal point => push ch to NB  letter => join NB contents as one Literal and push to result, then push ch to LB  operator => join NB contents as one Literal and push to result OR push LB contents separately as Variables, then push ch to result  LP => join LB contents as one Function and push to result OR (join NB contents as one Literal and push to result, push Operator * to result), then push ch to result  RP => join NB contents as one Literal and push to result OR push LB contents separately as Variables, then push ch to result"}, {"317f": "end loop"}, {"9b45": "join NB contents as one Literal and push to result OR push LB contents separately as Variables,"}, {"744e": "Two things to note."}, {"dd5d": "Translating It to\u00a0Code"}, {"d771": "Putting it all together, your tokenize function should look like this now (along with a little demo):"}, {"a4d9": "Yup. It works!"}, {"335d": "Yeah! Note the added *s for the implicit multiplications"}, {"a389": "Wrapping It\u00a0Up"}, {"6455": "This is the point where you analyze your function and measure what it does versus what you want it to do. Ask yourself questions like, \u201cDoes the function work as intended?\u201d and \u201cHave I covered all edge cases?\u201d"}, {"69c9": "Edge cases for this could include negative numbers and the like. You also run tests on the function. If at the end you are satisfied, you may then begin to seek out how you can improve it."}, {"b6f5": "Thanks for reading. Please click the little heart to recommend this article, and share if you enjoyed it! And if you have tried another approach for building a math tokenizer, do let me know in the comments."}], "content": "How to build a math expression tokenizer using JavaScript Source: Wikimedia Commons Some time ago, I got inspired to build an app for solving specific kinds of math problems. I discovered I had to parse the expression into an abstract syntax tree, so I decided to build a prototype in Javascript. While working on the parser, I realized the tokenizer had to be built first. I\u2019ll walk you through how to do one yourself. (Warning: its easier than it looks at first.) What is a Tokenizer? A tokenizer is a program that breaks up an expression into units called tokens. For instance, if we have an expression like \u201cI\u2019m a big fat developer\u201d, we could tokenize it in different ways, such as: Using words as tokens, 0 => I\u2019m1 => a2 => big3 => fat4 => developer Using non-whitespace characters as tokens, 0 => I1 => \u20182 => m3 => a4 => b\u202616 => p17 => e18 => r We could also consider all characters as tokens, to get 0 => I1 => \u20182 => m3 => (space)4 => a5 => (space)6 => b\u202620 => p21 => e22 => r You get the idea, right? Tokenizers (also called lexers) are used in the development of compilers for programming languages. They help the compiler make structural sense out of what you are trying to say. In this case, though, we\u2019re building one for math expressions. Tokens A valid math expression consists of mathematically valid tokens, which for the purposes of this project could be Literals, Variables, Operators or Functions.A few notes on the above: We\u2019ll also add two tokens that aren\u2019t usually considered tokens, but will help us with clarity: Left and Right Parentheses. You know what those are. A Few Considerations Implicit Multiplication Implicit multiplication simply means allowing the user to write \u201cshorthand\u201d multiplications, such as 5x, instead of 5*x. Taking it a step further, it also allows doing that with functions (5sin(x) = 5*sin(x)). Even further, it allows for 5(x) and 5(sin(x)). We have the option of allowing it or not. Tradeoffs? Not allowing it would actually make tokenizing easier and would allow for multi-letter variable names (names likeprice). Allowing it makes the platform more intuitive to the user, and well, provides an added challenge to overcome. I chose to allow it. Syntax While we aren\u2019t creating a programming language, we need to have some rules about what makes a valid expression, so users know what to enter and we know what to plan for. In precise terms, math tokens must be combined according to these syntax rules for the expression to be valid. Here are my rules: 2+3, 2 +3, 2 + 3, 2 + 3 are all OK 5 x - 22, 5x-22, 5x- 22 are all OK In other words, spacing doesn\u2019t matter (except within a multi-character token like the Literal 22). 2. Function arguments have to be in parentheses (sin(y), cos(45), not sin y, cos 45). (Why? We\u2019ll be removing all spaces from the string, so we want to know where a function starts and ends without having to do some \u201cgymnastics\u201d.) 3. Implicit multiplication is allowed only between Literals and Variables, or Literals and Functions, in that order (that is, Literals always come first), and can be with or without parentheses. This means: Now, let\u2019s get to work. Data Modelling It helps to have a sample expression in your head to test this on. We\u2019ll start with something basic: 2y + 1 What we expect is an array that lists the different tokens in the expression, along with their types and values. So for this case, we expect: 0 => Literal (2)1 => Variable (y)2 => Operator (+)3 => Literal (1) First, we\u2019ll define a Token class to make things easier: function Token(type, value) {   this.type = type;   this.value = value} Algorithm Next, let\u2019s build the skeleton of our tokenizer function. Our tokenizer will go through each character of the str array and build tokens based on the value it finds. [Note that we\u2019re assuming the user gives us a valid expression, so we\u2019ll skip any form of validation throughout this project.] function tokenize(str) {  var result=[]; //array of tokens    // remove spaces; remember they don't matter?  str.replace(/\\s+/g, \"\");   // convert to array of characters  str=str.split(\"\");   str.forEach(function (char, idx) {    if(isDigit(char)) {      result.push(new Token(\"Literal\", char));    } else if (isLetter(char)) {      result.push(new Token(\"Variable\", char));    } else if (isOperator(char)) {      result.push(new Token(\"Operator\", char));    } else if (isLeftParenthesis(char)) {      result.push(new Token(\"Left Parenthesis\", char));    } else if (isRightParenthesis(char)) {      result.push(new Token(\"Right Parenthesis\", char));    }  });   return result;} The code above is fairly basic. For reference, the helpers isDigit()\u00a0, isLetter(), isOperator(), isLeftParenthesis(), and isRightParenthesis()are defined as follows (don\u2019t be scared by the symbols\u200a\u2014\u200ait\u2019s called regex, and it\u2019s really awesome): function isDigit(ch) { return /\\d/.test(ch);} function isLetter(ch) { return /[a-z]/i.test(ch);} function isOperator(ch) { return /\\+|-|\\*|\\/|\\^/.test(ch);} function isLeftParenthesis(ch) { return /\\(/.test(ch);} function isRightParenthesis(ch) { return /\\)/.test(ch);} [Note that there are no isFunction(), isLiteral() or isVariable() functions, because we testing characters individually.] So now our parser actually works. Try it out on these expressions: 2 + 3, 4a + 1, 5x+ (2y), 11 + sin(20.4). All good? Not quite. You\u2019ll observe that for the last expression, 11 is reported as two Literal tokens instead of one. Also sin gets reported as three tokens instead of one. Why is this? Let\u2019s pause for a moment and think about this. We tokenized the array character by character, but actually, some of our tokens can contain multiple characters. For example, Literals can be 5, 7.9,\u00a0.5. Functions can be sin, cos etc. Variables are only single-characters, but can occur together in implicit multiplication. How do we solve this? Buffers We can fix this by implementing a buffer. Two, actually. We\u2019ll use one buffer to hold Literal characters (numbers and decimal point), and one for letters (which covers both variables and functions). How do the buffers work? When the tokenizer encounters a number/decimal point or letter, it pushes it into the appropriate buffer, and keeps doing so until it enters a different kind of operator. Its actions will vary based on the operator. For instance, in the expression 456.7xy + 6sin(7.04x), it should go along these lines:  read 4 => numberBuffer read 5 => numberBuffer read 6 => numberBuffer read\u00a0. => numberBuffer read 7 => numberBuffer x is\u00a0a\u00a0letter, so put all the contents of numberbuffer together as a Literal 456.7 => result read x => letterBuffer read y => letterBuffer + is an Operator, so remove all the contents of letterbuffer separately as Variables x => result, y => result + => result read 6 => numberBuffer s is a letter, so put all the contents of numberbuffer together as a Literal 6 => result read s => letterBuffer read i => letterBuffer read n => letterBuffer ( is a Left Parenthesis, so put all the contents of letterbuffer together as a function sin => result read 7 => numberBuffer read\u00a0. => numberBuffer read 0 => numberBuffer read 4 => numberBuffer x is a letter, so put all the contents of numberbuffer together as a Literal 7.04 => result read x => letterBuffer ) is a Right Parenthesis, so remove all the contents of letterbuffer separately as Variables x => result Complete. You get the hang of it now, right? We\u2019re getting there, just a few more cases to handle. This is the point where you sit down and think deeply about your algorithm and data modeling. What happens if my current character is an operator, and the numberBuffer is non-empty? Can both buffers ever simultaneously be non-empty? Putting it all together, here\u2019s what we come up with (the values to the left of the arrow depict our current character (ch) type, NB=numberbuffer, LB=letterbuffer, LP=left parenthesis, RP=right parenthesis loop through the array:  what type is ch?   digit => push ch to NB  decimal point => push ch to NB  letter => join NB contents as one Literal and push to result, then push ch to LB  operator => join NB contents as one Literal and push to result OR push LB contents separately as Variables, then push ch to result  LP => join LB contents as one Function and push to result OR (join NB contents as one Literal and push to result, push Operator * to result), then push ch to result  RP => join NB contents as one Literal and push to result OR push LB contents separately as Variables, then push ch to result end loop join NB contents as one Literal and push to result OR push LB contents separately as Variables, Two things to note. Translating It to\u00a0Code Putting it all together, your tokenize function should look like this now (along with a little demo): Yup. It works! Yeah! Note the added *s for the implicit multiplications Wrapping It\u00a0Up This is the point where you analyze your function and measure what it does versus what you want it to do. Ask yourself questions like, \u201cDoes the function work as intended?\u201d and \u201cHave I covered all edge cases?\u201d Edge cases for this could include negative numbers and the like. You also run tests on the function. If at the end you are satisfied, you may then begin to seek out how you can improve it. Thanks for reading. Please click the little heart to recommend this article, and share if you enjoyed it! And if you have tried another approach for building a math tokenizer, do let me know in the comments. ", "child": "868_1\t868_2\t868_3\t868_4\t868_5\t868_6\t868_7\t868_8\t868_9\t868_10\t868_11\t868_12\t868_13"}